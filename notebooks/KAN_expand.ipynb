{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import sys\n",
        "from collections import Counter, OrderedDict\n",
        "from pathlib import Path\n",
        "from typing import ClassVar, Iterator, Sequence\n",
        "import json\n",
        "\n",
        "# import mmh3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, matthews_corrcoef\n"
      ],
      "metadata": {
        "id": "iWeDk-z75g4m"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KAN Linear"
      ],
      "metadata": {
        "id": "vI0xJvw1SnDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class KANLinear(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=20,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = torch.nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = torch.nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
        "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the coefficients of the curve that interpolates the given points.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(\n",
        "            0, 1\n",
        "        )  # (in_features, batch_size, grid_size + spline_order)\n",
        "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
        "        solution = torch.linalg.lstsq(\n",
        "            A, B\n",
        "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
        "        result = solution.permute(\n",
        "            2, 0, 1\n",
        "        )  # (out_features, in_features, grid_size + spline_order)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.size(-1) == self.in_features\n",
        "        original_shape = x.shape\n",
        "        x = x.reshape(-1, self.in_features)\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        output = base_output + spline_output\n",
        "\n",
        "        output = output.reshape(*original_shape[:-1], self.out_features)\n",
        "        return output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
        "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
        "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # (batch, in, out)\n",
        "\n",
        "        # sort each channel individually to collect data distribution\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.concatenate(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        \"\"\"\n",
        "        Compute the regularization loss.\n",
        "\n",
        "        This is a dumb simulation of the original L1 regularization as stated in the\n",
        "        paper, since the original one requires computing absolutes and entropy from the\n",
        "        expanded (batch, in_features, out_features) intermediate tensor, which is hidden\n",
        "        behind the F.linear function if we want an memory efficient implementation.\n",
        "\n",
        "        The L1 regularization is now computed as mean absolute value of the spline\n",
        "        weights. The authors implementation also includes this term in addition to the\n",
        "        sample-based regularization.\n",
        "        \"\"\"\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "\n",
        "class KAN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=20,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                KANLinear(\n",
        "                    in_features,\n",
        "                    out_features,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=True):\n",
        "        for layer in self.layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        return sum(\n",
        "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
        "            for layer in self.layers\n",
        "        )"
      ],
      "metadata": {
        "id": "pTu2V80lvv6t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KAN Conv"
      ],
      "metadata": {
        "id": "lTlxIJIGPr7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Util\n",
        "def add_padding_1d(array: np.ndarray, padding: int) -> np.ndarray:\n",
        "    \"\"\"Adds padding to a 1D array.\"\"\"\n",
        "    n = array.shape[0]\n",
        "    padded_array = np.zeros(n + 2 * padding)\n",
        "    padded_array[padding: n + padding] = array\n",
        "    return padded_array\n",
        "\n",
        "\n",
        "def calc_out_dims_1d(array, kernel_size, stride, dilation, padding):\n",
        "    \"\"\"Calculate output dimensions for 1D convolution.\"\"\"\n",
        "    batch_size, n_channels, n = matrix.shape\n",
        "    out_size = np.floor((n + 2 * padding - kernel_size - (kernel_size - 1) * (dilation - 1)) / stride).astype(int) + 1\n",
        "    return out_size, batch_size, n_channels\n",
        "\n",
        "\n",
        "def multiple_convs_kan_conv1d(array,\n",
        "                               kernels,\n",
        "                               kernel_size,\n",
        "                               out_channels,\n",
        "                               stride=1,\n",
        "                               dilation=1,\n",
        "                               padding=0,\n",
        "                               device=\"cuda\") -> torch.Tensor:\n",
        "    \"\"\"Performs a 1D convolution with multiple kernels on the input array using specified stride, dilation, and padding.\n",
        "\n",
        "    Args:\n",
        "        array (torch.Tensor): 1D tensor of shape (batch_size, channels, length).\n",
        "        kernels (list): List of kernel functions to be applied.\n",
        "        kernel_size (int): Size of the 1D kernel.\n",
        "        out_channels (int): Number of output channels.\n",
        "        stride (int): Stride along the length of the array. Default is 1.\n",
        "        dilation (int): Dilation rate along the length of the array. Default is 1.\n",
        "        padding (int): Number of elements to pad on each side. Default is 0.\n",
        "        device (str): Device to perform calculations on. Default is \"cuda\".\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Feature map after convolution with shape (batch_size, out_channels, length_out).\n",
        "    \"\"\"\n",
        "    length_out, batch_size = calc_out_dims_1d(array, kernel_size, stride, dilation, padding)\n",
        "    n_convs = len(kernels)\n",
        "\n",
        "    array_out = torch.zeros((batch_size, out_channels, length_out)).to(device)\n",
        "\n",
        "    array = F.pad(array, (padding, padding), mode='constant', value=0)\n",
        "    conv_groups = array.unfold(2, kernel_size, stride)\n",
        "    conv_groups = conv_groups.contiguous()\n",
        "\n",
        "    kern_per_out = len(kernels) // out_channels\n",
        "\n",
        "    for c_out in range(out_channels):\n",
        "        out_channel_accum = torch.zeros((batch_size, length_out), device=device)\n",
        "\n",
        "        for k_idx in range(kern_per_out):\n",
        "            kernel = kernels[c_out * kern_per_out + k_idx]\n",
        "            conv_result = kernel(conv_groups.view(-1, 1, kernel_size))\n",
        "            out_channel_accum += conv_result.view(batch_size, length_out)\n",
        "\n",
        "        array_out[:, c_out, :] = out_channel_accum\n",
        "\n",
        "    return array_out"
      ],
      "metadata": {
        "id": "4UbM_j1ePw-j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kan_conv1d(matrix: torch.Tensor,\n",
        "               kernel,\n",
        "               kernel_size: int,\n",
        "               stride: int = 1,\n",
        "               dilation: int = 1,\n",
        "               padding: int = 0,\n",
        "               device: str = \"cpu\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Performs a 1D convolution with the given kernel over a 1D matrix using the defined stride, dilation, and padding.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): 3D tensor (batch_size, channels, width) to be convolved.\n",
        "        kernel (function): Kernel function to apply on the 1D patches of the matrix.\n",
        "        kernel_size (int): Size of the kernel (assumed to be square).\n",
        "        stride (int, optional): Stride along the width axis. Defaults to 1.\n",
        "        dilation (int, optional): Dilation along the width axis. Defaults to 1.\n",
        "        padding (int, optional): Padding along the width axis. Defaults to 0.\n",
        "        device (str): Device to perform the operation on (e.g., \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 1D Feature map after convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, n_channels, width_in = matrix.shape\n",
        "    width_out = ((width_in + 2 * padding - dilation * (kernel_size - 1) - 1) // stride) + 1\n",
        "    matrix_out = torch.zeros((batch_size, n_channels, width_out), device=device)\n",
        "\n",
        "    matrix_padded = torch.nn.functional.pad(matrix, (padding, padding))\n",
        "\n",
        "    for i in range(width_out):\n",
        "\n",
        "        start = i * stride\n",
        "        end = start + kernel_size * dilation\n",
        "        patch = matrix_padded[:, :, start:end:dilation]\n",
        "\n",
        "        matrix_out[:, :, i] = kernel.forward(patch).squeeze(-1)\n",
        "\n",
        "    return matrix_out"
      ],
      "metadata": {
        "id": "YMJ86gElPxBC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KAN_Convolutional_Layer_1D(torch.nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1, kernel_size=5, stride=1, padding=0, dilation=1, device=\"cuda\"):\n",
        "        super(KAN_Convolutional_Layer_1D, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.device = device\n",
        "        self.convs = torch.nn.ModuleList([KAN_Convolution_1D(kernel_size, stride, padding, dilation, device) for _ in range(in_channels * out_channels)])\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return torch.cat([conv(x[:, i, :].unsqueeze(1)) for i, conv in enumerate(self.convs)], dim=1)"
      ],
      "metadata": {
        "id": "k7vXkJNbPxDz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class KAN_Convolutional_Layer_1D(torch.nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int = 1,\n",
        "            out_channels: int = 1,\n",
        "            kernel_size: int = 2,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            dilation: int = 1,\n",
        "            grid_size: int = 5,\n",
        "            spline_order: int = 3,\n",
        "            scale_noise: float = 0.1,\n",
        "            scale_base: float = 1.0,\n",
        "            scale_spline: float = 1.0,\n",
        "            base_activation=torch.nn.SiLU,\n",
        "            grid_eps: float = 0.02,\n",
        "            grid_range: tuple = [-1, 1],\n",
        "            device: str = \"cpu\"\n",
        "        ):\n",
        "        super(KAN_Convolutional_Layer_1D, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.in_channels = in_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(in_channels * out_channels):\n",
        "            self.convs.append(\n",
        "                KAN_Convolution_1D(\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=stride,\n",
        "                    padding=padding,\n",
        "                    dilation=dilation,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        batch_size, in_channels, length = x.shape\n",
        "        output_length = (length + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1) // self.stride + 1\n",
        "        output = torch.zeros((batch_size, self.out_channels, output_length), device=x.device)\n",
        "\n",
        "\n",
        "        for i in range(self.out_channels):\n",
        "            output_accum = torch.zeros((batch_size, output_length), device=x.device)\n",
        "            for j in range(self.in_channels):\n",
        "                kernel_idx = i * self.in_channels + j\n",
        "                conv_result = self.convs[kernel_idx].forward(x[:, j, :].unsqueeze(1))\n",
        "                output_accum += conv_result.squeeze(1)  # Squeeze\n",
        "            output[:, i, :] = output_accum  # A to output channel\n",
        "\n",
        "        return output\n",
        "\n",
        "class KAN_Convolution_1D(torch.nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            kernel_size: int = 2,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            dilation: int = 1,\n",
        "            grid_size: int = 50,\n",
        "            spline_order: int = 3,\n",
        "            scale_noise: float = 0.1,\n",
        "            scale_base: float = 1.0,\n",
        "            scale_spline: float = 1.0,\n",
        "            base_activation=torch.nn.SiLU,\n",
        "            grid_eps: float = 0.02,\n",
        "            grid_range: tuple = [-1, 1]\n",
        "        ):\n",
        "        super(KAN_Convolution_1D, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.conv = KANLinear(\n",
        "            in_features = kernel_size,\n",
        "            out_features = 1,\n",
        "            grid_size=grid_size,\n",
        "            spline_order=spline_order,\n",
        "            scale_noise=scale_noise,\n",
        "            scale_base=scale_base,\n",
        "            scale_spline=scale_spline,\n",
        "            base_activation=base_activation,\n",
        "            grid_eps=grid_eps,\n",
        "            grid_range=grid_range\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        self.device = x.device\n",
        "        return kan_conv1d(x, self.conv, self.kernel_size,self.stride, self.dilation, self.padding, self.device)"
      ],
      "metadata": {
        "id": "wNgoVQDoP4nD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example with changed mapper"
      ],
      "metadata": {
        "id": "4aF6i9lzP9Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bilinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Simplified Bilinear layer that uses a single Linear layer for pairwise interaction.\n",
        "    \"\"\"\n",
        "    def __init__(self, n: int, out=None, bias=False):\n",
        "        super().__init__()\n",
        "        if out is None:\n",
        "            out = n\n",
        "        self.fc = nn.Linear(n, out, bias=bias)\n",
        "        # self.fc = KANLinear(n, out)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "class SELayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Simplified Squeeze-and-Excite layer.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    inp : int\n",
        "        Middle layer size.\n",
        "    oup : int\n",
        "        Input and output size.\n",
        "    reduction : int, optional\n",
        "        Reduction parameter. Default is 4.\n",
        "    \"\"\"\n",
        "    def __init__(self, inp, oup, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            # KANLinear(oup, inp // reduction),\n",
        "            nn.Linear(oup, inp // reduction, bias=False),\n",
        "            nn.SiLU(),\n",
        "            # KANLinear(inp // reduction, oup),\n",
        "            nn.Linear(inp // reduction, oup, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _ = x.size()\n",
        "        y = x.view(b, c, -1).mean(dim=2)  # Global Average Pooling\n",
        "        y = self.fc(y).view(b, c, 1)\n",
        "        return x * y\n",
        "\n",
        "# Main SeqNN model\n",
        "class SeqNN(nn.Module):\n",
        "    \"\"\"\n",
        "    LegNet neural network for binary classification.\n",
        "    \"\"\"\n",
        "    __constants__ = ('resize_factor')\n",
        "\n",
        "    def __init__(self,\n",
        "                seqsize,\n",
        "                use_single_channel,\n",
        "                use_reverse_channel,\n",
        "                use_multisubstate_channel,\n",
        "                block_sizes=[256, 256, 128, 128, 64, 64, 32, 32],\n",
        "                ks=5,\n",
        "                resize_factor=4,\n",
        "                activation=nn.SiLU,\n",
        "                filter_per_group=2,\n",
        "                se_reduction=4,\n",
        "                final_ch=1,\n",
        "                bn_momentum=0.1):\n",
        "        super().__init__()\n",
        "        self.block_sizes = block_sizes\n",
        "        self.resize_factor = resize_factor\n",
        "        self.se_reduction = se_reduction\n",
        "        self.seqsize = seqsize\n",
        "        self.use_single_channel = use_single_channel\n",
        "        self.use_reverse_channel = use_reverse_channel\n",
        "        self.use_multisubstate_channel = use_multisubstate_channel\n",
        "        self.final_ch = final_ch\n",
        "        self.bn_momentum = bn_momentum\n",
        "        seqextblocks = OrderedDict()\n",
        "\n",
        "        in_channels_first_block = 4\n",
        "        if self.use_single_channel:\n",
        "            in_channels_first_block += 1\n",
        "        if self.use_reverse_channel:\n",
        "            in_channels_first_block += 1\n",
        "        if self.use_multisubstate_channel:\n",
        "            in_channels_first_block += 1\n",
        "\n",
        "        block = nn.Sequential(\n",
        "            nn.Conv1d(\n",
        "                in_channels=in_channels_first_block,\n",
        "                out_channels=block_sizes[0],\n",
        "                kernel_size=ks,\n",
        "                padding='same',\n",
        "                bias=False\n",
        "            ),\n",
        "            nn.BatchNorm1d(block_sizes[0], momentum=self.bn_momentum),\n",
        "            activation()\n",
        "        )\n",
        "        seqextblocks['blc0'] = block\n",
        "\n",
        "        # Building remaining blocks\n",
        "        for ind, (prev_sz, sz) in enumerate(zip(block_sizes[:-1], block_sizes[1:])):\n",
        "            block = nn.Sequential(\n",
        "                nn.Conv1d(prev_sz, sz * self.resize_factor, kernel_size=1, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
        "                activation(),\n",
        "\n",
        "                nn.Conv1d(sz * self.resize_factor, sz * self.resize_factor, kernel_size=ks,\n",
        "                          groups=sz * self.resize_factor // filter_per_group, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(sz * self.resize_factor, momentum=self.bn_momentum),\n",
        "                activation(),\n",
        "\n",
        "                SELayer(prev_sz, sz * self.resize_factor, reduction=self.se_reduction),\n",
        "\n",
        "                nn.Conv1d(sz * self.resize_factor, prev_sz, kernel_size=1, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(prev_sz, momentum=self.bn_momentum),\n",
        "                activation(),\n",
        "            )\n",
        "            seqextblocks[f'inv_res_blc{ind}'] = block\n",
        "\n",
        "            resize_block = nn.Sequential(\n",
        "                nn.Conv1d(2 * prev_sz, sz, kernel_size=ks, padding='same', bias=False),\n",
        "                nn.BatchNorm1d(sz, momentum=self.bn_momentum),\n",
        "                activation()\n",
        "            )\n",
        "            seqextblocks[f'resize_blc{ind}'] = resize_block\n",
        "\n",
        "        self.seqextractor = nn.ModuleDict(seqextblocks)\n",
        "\n",
        "        self.mapper = nn.Sequential(\n",
        "            nn.Conv1d(block_sizes[-1], self.final_ch, kernel_size=1, padding='same'),\n",
        "            activation()\n",
        "        )\n",
        "\n",
        "        self.register_buffer('bins', torch.arange(start=0, end=self.final_ch, step=1, requires_grad=False))\n",
        "\n",
        "    def feature_extractor(self, x):\n",
        "        x = self.seqextractor['blc0'](x)\n",
        "        for i in range(len(self.block_sizes) - 1):\n",
        "            x = torch.cat([x, self.seqextractor[f'inv_res_blc{i}'](x)], dim=1)\n",
        "            x = self.seqextractor[f'resize_blc{i}'](x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        f = self.feature_extractor(x)\n",
        "        x = self.mapper(f)\n",
        "        x = F.adaptive_avg_pool1d(x, 1)\n",
        "        x = x.squeeze(2)\n",
        "        prob = torch.sigmoid(x).squeeze(1)\n",
        "\n",
        "        return prob\n",
        "        # logprobs = F.log_softmax(x, dim=1)\n",
        "\n",
        "        # # Soft-argmax operation (optional)\n",
        "        # x = F.softmax(x, dim=1)\n",
        "        # score = (x * self.bins).sum(dim=1)\n",
        "\n",
        "        # return logprobs, score"
      ],
      "metadata": {
        "id": "kmaXRmAdP4q6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_map = {\n",
        "    \"A\": [1, 0, 0, 0],\n",
        "    \"T\": [0, 1, 0, 0],\n",
        "    \"C\": [0, 0, 1, 0],\n",
        "    \"G\": [0, 0, 0, 1,]\n",
        "}"
      ],
      "metadata": {
        "id": "fIoKlbf84xHR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "PzqUJs3V5Sib"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "RMcNNTsP7F-U"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SeqNN(\n",
        "    seqsize=500,\n",
        "    use_single_channel=False,\n",
        "    use_reverse_channel=False,\n",
        "    use_multisubstate_channel=False,\n",
        "    final_ch=1  # For binary classification\n",
        ")\n",
        "# criterion = nn.BCEWithLogitsLoss()  # Binary classification with logits\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.005)\n"
      ],
      "metadata": {
        "id": "UNgMwQp57y-x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayyNG-mq8Ard",
        "outputId": "593b15d3-6120-43a8-d54c-3063a7722db5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SeqNN(\n",
              "  (seqextractor): ModuleDict(\n",
              "    (blc0): Sequential(\n",
              "      (0): Conv1d(4, 256, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc0): Sequential(\n",
              "      (0): Conv1d(256, 1024, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(1024, 1024, kernel_size=(5,), stride=(1,), padding=same, groups=512, bias=False)\n",
              "      (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=1024, out_features=64, bias=False)\n",
              "          (1): SiLU()\n",
              "          (2): Linear(in_features=64, out_features=1024, bias=False)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(1024, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc0): Sequential(\n",
              "      (0): Conv1d(512, 256, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc1): Sequential(\n",
              "      (0): Conv1d(256, 512, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=same, groups=256, bias=False)\n",
              "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=64, bias=False)\n",
              "          (1): SiLU()\n",
              "          (2): Linear(in_features=64, out_features=512, bias=False)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(512, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc1): Sequential(\n",
              "      (0): Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc2): Sequential(\n",
              "      (0): Conv1d(128, 512, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=same, groups=256, bias=False)\n",
              "      (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=32, bias=False)\n",
              "          (1): SiLU()\n",
              "          (2): Linear(in_features=32, out_features=512, bias=False)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(512, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc2): Sequential(\n",
              "      (0): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc3): Sequential(\n",
              "      (0): Conv1d(128, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=same, groups=128, bias=False)\n",
              "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=256, out_features=32, bias=False)\n",
              "          (1): SiLU()\n",
              "          (2): Linear(in_features=32, out_features=256, bias=False)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(256, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc3): Sequential(\n",
              "      (0): Conv1d(256, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc4): Sequential(\n",
              "      (0): Conv1d(64, 256, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=same, groups=128, bias=False)\n",
              "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=256, out_features=16, bias=False)\n",
              "          (1): SiLU()\n",
              "          (2): Linear(in_features=16, out_features=256, bias=False)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(256, 64, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc4): Sequential(\n",
              "      (0): Conv1d(128, 64, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc5): Sequential(\n",
              "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, groups=64, bias=False)\n",
              "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=16, bias=False)\n",
              "          (1): SiLU()\n",
              "          (2): Linear(in_features=16, out_features=128, bias=False)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(128, 64, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc5): Sequential(\n",
              "      (0): Conv1d(128, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "    (inv_res_blc6): Sequential(\n",
              "      (0): Conv1d(32, 128, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "      (3): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=same, groups=64, bias=False)\n",
              "      (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): SiLU()\n",
              "      (6): SELayer(\n",
              "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
              "        (fc): Sequential(\n",
              "          (0): Linear(in_features=128, out_features=8, bias=False)\n",
              "          (1): SiLU()\n",
              "          (2): Linear(in_features=8, out_features=128, bias=False)\n",
              "          (3): Sigmoid()\n",
              "        )\n",
              "      )\n",
              "      (7): Conv1d(128, 32, kernel_size=(1,), stride=(1,), padding=same, bias=False)\n",
              "      (8): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (9): SiLU()\n",
              "    )\n",
              "    (resize_blc6): Sequential(\n",
              "      (0): Conv1d(64, 32, kernel_size=(5,), stride=(1,), padding=same, bias=False)\n",
              "      (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): SiLU()\n",
              "    )\n",
              "  )\n",
              "  (mapper): Sequential(\n",
              "    (0): Conv1d(32, 1, kernel_size=(1,), stride=(1,), padding=same)\n",
              "    (1): SiLU()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB0Z02CDwoLd",
        "outputId": "e96b7479-1188-43a4-84ab-c9fce220a1a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 2649313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv(\"/content/train.csv\")\n",
        "df_dev = pd.read_csv(\"/content/dev.csv\")\n",
        "df_test = pd.read_csv(\"/content/test.csv\")"
      ],
      "metadata": {
        "id": "xKob5ageF8B5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train[\"sequence\"][0])"
      ],
      "metadata": {
        "id": "1YT2VLuOF9Nm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9098e73d-cc07-4b7d-e7ee-0ab64933177a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "taGBqcU-GBHy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_map = {\n",
        "    \"A\": [1, 0, 0, 0],\n",
        "    \"T\": [0, 1, 0, 0],\n",
        "    \"C\": [0, 0, 1, 0],\n",
        "    \"G\": [0, 0, 0, 1]\n",
        "}"
      ],
      "metadata": {
        "id": "7HqMlFBlGECA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sequence(sequence):\n",
        "    encoded_seq = [encoding_map[base] for base in sequence if base in encoding_map]\n",
        "    return torch.tensor(encoded_seq, dtype=torch.float).t()\n",
        "\n",
        "def pad_sequences(sequences, target_length):\n",
        "    padded_sequences = []\n",
        "    for seq in sequences:\n",
        "        seq_len = seq.size(1)\n",
        "        if seq_len < target_length:\n",
        "            left_padding = (target_length - seq_len) // 2\n",
        "            right_padding = target_length - seq_len - left_padding\n",
        "            padded_seq = torch.nn.functional.pad(seq, (left_padding, right_padding))\n",
        "        else:\n",
        "            padded_seq = seq[:, :target_length]\n",
        "        padded_sequences.append(padded_seq)\n",
        "    return torch.stack(padded_sequences)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sequences, labels = zip(*batch)\n",
        "    sequence_lengths = [seq.size(1) for seq in sequences]\n",
        "    target_length = int(np.median(sequence_lengths))\n",
        "    padded_sequences = pad_sequences(sequences, target_length)\n",
        "    labels = torch.stack(labels)\n",
        "    return padded_sequences, labels"
      ],
      "metadata": {
        "id": "qp15g0n2GGzd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DNASequencesDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.data = dataframe\n",
        "        self.data = self.data[~self.data['sequence'].str.contains('N')].reset_index(drop=True)\n",
        "        self.encoded_sequences = [encode_sequence(seq) for seq in self.data['sequence']]\n",
        "        self.labels = torch.tensor(self.data['label'].values, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_sequences[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "scoHGcVHGJsy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DNASequencesDataset(df_train)\n",
        "dev_dataset = DNASequencesDataset(df_dev)\n",
        "test_dataset = DNASequencesDataset(df_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=False)"
      ],
      "metadata": {
        "id": "2yBWOMJ2GMsw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    for sequences, labels in loader:\n",
        "        sequences, labels = sequences.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        probs = model(sequences)\n",
        "        loss = criterion(probs, labels.float())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * sequences.size(0)\n",
        "        all_preds.extend(probs.detach().cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(loader.dataset)\n",
        "\n",
        "    all_preds = [1 if p >= 0.5 else 0 for p in all_preds]\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, accuracy, f1, auc, precision, recall, mcc\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    eval_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in loader:\n",
        "            sequences, labels = sequences.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            probs = model(sequences)\n",
        "            loss = criterion(probs, labels.float())\n",
        "            eval_loss += loss.item() * sequences.size(0)\n",
        "\n",
        "            all_preds.extend(probs.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    epoch_loss = eval_loss / len(loader.dataset)\n",
        "\n",
        "    all_preds = [1 if p >= 0.5 else 0 for p in all_preds]\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    auc = roc_auc_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "    return epoch_loss, accuracy, f1, auc, precision, recall, mcc"
      ],
      "metadata": {
        "id": "LZTcEl9OGRU5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    train_loss, train_acc, train_f1, train_auc, train_precision, train_recall, train_mcc = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, val_auc, val_precision, val_recall, val_mcc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}, AUC: {train_auc:.4f}, \"\n",
        "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, MCC: {train_mcc:.4f}\")\n",
        "    print(f\"Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}, AUC: {val_auc:.4f}, \"\n",
        "          f\"Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, MCC: {val_mcc:.4f}\")\n"
      ],
      "metadata": {
        "id": "aMuuhLc3Gscm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a055e7-2e38-474d-b325-40be0a078761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "Train - Loss: 0.5375, Acc: 0.7979, F1: 0.8049, AUC: 0.7976, Precision: 0.7986, Recall: 0.8112, MCC: 0.5954\n",
            "Val   - Loss: 0.7041, Acc: 0.6900, F1: 0.7611, AUC: 0.6875, Precision: 0.6226, Recall: 0.9788, MCC: 0.4627\n",
            "Epoch 2/500\n",
            "Train - Loss: 0.4917, Acc: 0.8386, F1: 0.8422, AUC: 0.8386, Precision: 0.8463, Recall: 0.8380, MCC: 0.6771\n",
            "Val   - Loss: 0.5874, Acc: 0.7021, F1: 0.6195, AUC: 0.7040, Precision: 0.8705, Recall: 0.4808, MCC: 0.4551\n",
            "Epoch 3/500\n",
            "Train - Loss: 0.4760, Acc: 0.8440, F1: 0.8459, AUC: 0.8442, Precision: 0.8585, Recall: 0.8337, MCC: 0.6882\n",
            "Val   - Loss: 0.5296, Acc: 0.8216, F1: 0.8394, AUC: 0.8207, Precision: 0.7687, Recall: 0.9245, MCC: 0.6565\n",
            "Epoch 4/500\n",
            "Train - Loss: 0.4620, Acc: 0.8541, F1: 0.8562, AUC: 0.8543, Precision: 0.8670, Recall: 0.8457, MCC: 0.7083\n",
            "Val   - Loss: 0.4870, Acc: 0.8390, F1: 0.8290, AUC: 0.8396, Precision: 0.8930, Recall: 0.7735, MCC: 0.6846\n",
            "Epoch 5/500\n",
            "Train - Loss: 0.4569, Acc: 0.8551, F1: 0.8563, AUC: 0.8556, Precision: 0.8731, Recall: 0.8402, MCC: 0.7109\n",
            "Val   - Loss: 0.5253, Acc: 0.8370, F1: 0.8492, AUC: 0.8364, Precision: 0.7961, Recall: 0.9099, MCC: 0.6807\n",
            "Epoch 6/500\n",
            "Train - Loss: 0.4498, Acc: 0.8638, F1: 0.8656, AUC: 0.8641, Precision: 0.8781, Recall: 0.8535, MCC: 0.7280\n",
            "Val   - Loss: 0.4706, Acc: 0.8530, F1: 0.8438, AUC: 0.8536, Precision: 0.9096, Recall: 0.7868, MCC: 0.7130\n",
            "Epoch 7/500\n",
            "Train - Loss: 0.4408, Acc: 0.8715, F1: 0.8739, AUC: 0.8717, Precision: 0.8814, Recall: 0.8665, MCC: 0.7431\n",
            "Val   - Loss: 0.4685, Acc: 0.8657, F1: 0.8666, AUC: 0.8657, Precision: 0.8684, Recall: 0.8649, MCC: 0.7315\n",
            "Epoch 8/500\n",
            "Train - Loss: 0.4346, Acc: 0.8748, F1: 0.8762, AUC: 0.8751, Precision: 0.8905, Recall: 0.8623, MCC: 0.7500\n",
            "Val   - Loss: 0.4821, Acc: 0.8544, F1: 0.8613, AUC: 0.8540, Precision: 0.8286, Recall: 0.8967, MCC: 0.7110\n",
            "Epoch 9/500\n",
            "Train - Loss: 0.4275, Acc: 0.8801, F1: 0.8805, AUC: 0.8807, Precision: 0.9024, Recall: 0.8597, MCC: 0.7613\n",
            "Val   - Loss: 0.4947, Acc: 0.8090, F1: 0.7769, AUC: 0.8103, Precision: 0.9450, Recall: 0.6596, MCC: 0.6496\n",
            "Epoch 10/500\n",
            "Train - Loss: 0.4217, Acc: 0.8831, F1: 0.8840, AUC: 0.8836, Precision: 0.9019, Recall: 0.8668, MCC: 0.7670\n",
            "Val   - Loss: 0.5241, Acc: 0.8377, F1: 0.8533, AUC: 0.8368, Precision: 0.7838, Recall: 0.9364, MCC: 0.6882\n",
            "Epoch 11/500\n",
            "Train - Loss: 0.4146, Acc: 0.8890, F1: 0.8898, AUC: 0.8894, Precision: 0.9075, Recall: 0.8728, MCC: 0.7786\n",
            "Val   - Loss: 0.4663, Acc: 0.8677, F1: 0.8653, AUC: 0.8680, Precision: 0.8895, Recall: 0.8424, MCC: 0.7366\n",
            "Epoch 12/500\n",
            "Train - Loss: 0.4144, Acc: 0.8881, F1: 0.8888, AUC: 0.8886, Precision: 0.9076, Recall: 0.8707, MCC: 0.7769\n",
            "Val   - Loss: 0.4690, Acc: 0.8657, F1: 0.8624, AUC: 0.8660, Precision: 0.8924, Recall: 0.8344, MCC: 0.7332\n",
            "Epoch 13/500\n",
            "Train - Loss: 0.4041, Acc: 0.8932, F1: 0.8936, AUC: 0.8937, Precision: 0.9151, Recall: 0.8730, MCC: 0.7873\n",
            "Val   - Loss: 0.5276, Acc: 0.8377, F1: 0.8490, AUC: 0.8371, Precision: 0.7998, Recall: 0.9046, MCC: 0.6810\n",
            "Epoch 14/500\n",
            "Train - Loss: 0.3919, Acc: 0.9034, F1: 0.9035, AUC: 0.9041, Precision: 0.9283, Recall: 0.8800, MCC: 0.8082\n",
            "Val   - Loss: 0.5136, Acc: 0.8604, F1: 0.8663, AUC: 0.8601, Precision: 0.8379, Recall: 0.8967, MCC: 0.7224\n",
            "Epoch 15/500\n",
            "Train - Loss: 0.3876, Acc: 0.9040, F1: 0.9030, AUC: 0.9050, Precision: 0.9389, Recall: 0.8698, MCC: 0.8106\n",
            "Val   - Loss: 0.4950, Acc: 0.8677, F1: 0.8669, AUC: 0.8679, Precision: 0.8799, Recall: 0.8543, MCC: 0.7358\n",
            "Epoch 16/500\n",
            "Train - Loss: 0.3770, Acc: 0.9117, F1: 0.9112, AUC: 0.9125, Precision: 0.9425, Recall: 0.8820, MCC: 0.8254\n",
            "Val   - Loss: 0.4798, Acc: 0.8290, F1: 0.8081, AUC: 0.8300, Precision: 0.9309, Recall: 0.7139, MCC: 0.6776\n",
            "Epoch 17/500\n",
            "Train - Loss: 0.3725, Acc: 0.9161, F1: 0.9154, AUC: 0.9171, Precision: 0.9497, Recall: 0.8836, MCC: 0.8346\n",
            "Val   - Loss: 0.4971, Acc: 0.8537, F1: 0.8489, AUC: 0.8541, Precision: 0.8862, Recall: 0.8146, MCC: 0.7100\n",
            "Epoch 18/500\n",
            "Train - Loss: 0.3739, Acc: 0.9130, F1: 0.9122, AUC: 0.9139, Precision: 0.9467, Recall: 0.8802, MCC: 0.8283\n",
            "Val   - Loss: 0.4858, Acc: 0.8544, F1: 0.8471, AUC: 0.8549, Precision: 0.9001, Recall: 0.8000, MCC: 0.7135\n",
            "Epoch 19/500\n",
            "Train - Loss: 0.3697, Acc: 0.9171, F1: 0.9165, AUC: 0.9180, Precision: 0.9501, Recall: 0.8852, MCC: 0.8365\n",
            "Val   - Loss: 0.5240, Acc: 0.8631, F1: 0.8683, AUC: 0.8628, Precision: 0.8429, Recall: 0.8954, MCC: 0.7274\n",
            "Epoch 20/500\n",
            "Train - Loss: 0.3606, Acc: 0.9254, F1: 0.9249, AUC: 0.9263, Precision: 0.9580, Recall: 0.8940, MCC: 0.8530\n",
            "Val   - Loss: 0.4983, Acc: 0.8611, F1: 0.8613, AUC: 0.8611, Precision: 0.8671, Recall: 0.8556, MCC: 0.7222\n",
            "Epoch 21/500\n",
            "Train - Loss: 0.3578, Acc: 0.9286, F1: 0.9281, AUC: 0.9295, Precision: 0.9608, Recall: 0.8976, MCC: 0.8593\n",
            "Val   - Loss: 0.5057, Acc: 0.8550, F1: 0.8509, AUC: 0.8554, Precision: 0.8843, Recall: 0.8199, MCC: 0.7122\n",
            "Epoch 22/500\n",
            "Train - Loss: 0.3510, Acc: 0.9337, F1: 0.9335, AUC: 0.9344, Precision: 0.9624, Recall: 0.9063, MCC: 0.8690\n",
            "Val   - Loss: 0.5366, Acc: 0.8604, F1: 0.8617, AUC: 0.8604, Precision: 0.8611, Recall: 0.8623, MCC: 0.7208\n",
            "Epoch 23/500\n",
            "Train - Loss: 0.3516, Acc: 0.9340, F1: 0.9338, AUC: 0.9348, Precision: 0.9632, Recall: 0.9062, MCC: 0.8697\n",
            "Val   - Loss: 0.4754, Acc: 0.8651, F1: 0.8589, AUC: 0.8655, Precision: 0.9084, Recall: 0.8146, MCC: 0.7343\n",
            "Epoch 24/500\n",
            "Train - Loss: 0.3477, Acc: 0.9346, F1: 0.9342, AUC: 0.9355, Precision: 0.9671, Recall: 0.9034, MCC: 0.8713\n",
            "Val   - Loss: 0.6234, Acc: 0.8363, F1: 0.8410, AUC: 0.8361, Precision: 0.8244, Recall: 0.8583, MCC: 0.6731\n",
            "Epoch 25/500\n",
            "Train - Loss: 0.3815, Acc: 0.9123, F1: 0.9116, AUC: 0.9132, Precision: 0.9455, Recall: 0.8800, MCC: 0.8269\n",
            "Val   - Loss: 0.4724, Acc: 0.8484, F1: 0.8380, AUC: 0.8490, Precision: 0.9087, Recall: 0.7775, MCC: 0.7046\n",
            "Epoch 26/500\n",
            "Train - Loss: 0.3446, Acc: 0.9368, F1: 0.9360, AUC: 0.9378, Precision: 0.9747, Recall: 0.9003, MCC: 0.8764\n",
            "Val   - Loss: 0.5009, Acc: 0.8550, F1: 0.8523, AUC: 0.8553, Precision: 0.8768, Recall: 0.8291, MCC: 0.7113\n",
            "Epoch 27/500\n",
            "Train - Loss: 0.3403, Acc: 0.9431, F1: 0.9433, AUC: 0.9438, Precision: 0.9674, Recall: 0.9203, MCC: 0.8874\n",
            "Val   - Loss: 0.5098, Acc: 0.8611, F1: 0.8630, AUC: 0.8610, Precision: 0.8585, Recall: 0.8675, MCC: 0.7221\n",
            "Epoch 28/500\n",
            "Train - Loss: 0.3418, Acc: 0.9404, F1: 0.9402, AUC: 0.9412, Precision: 0.9702, Recall: 0.9120, MCC: 0.8827\n",
            "Val   - Loss: 0.5344, Acc: 0.8437, F1: 0.8393, AUC: 0.8440, Precision: 0.8716, Recall: 0.8093, MCC: 0.6893\n",
            "Epoch 29/500\n",
            "Train - Loss: 0.3316, Acc: 0.9495, F1: 0.9494, AUC: 0.9502, Precision: 0.9773, Recall: 0.9231, MCC: 0.9005\n",
            "Val   - Loss: 0.5364, Acc: 0.8644, F1: 0.8622, AUC: 0.8646, Precision: 0.8844, Recall: 0.8411, MCC: 0.7298\n",
            "Epoch 30/500\n",
            "Train - Loss: 0.3373, Acc: 0.9427, F1: 0.9425, AUC: 0.9435, Precision: 0.9725, Recall: 0.9143, MCC: 0.8872\n",
            "Val   - Loss: 0.5296, Acc: 0.8717, F1: 0.8701, AUC: 0.8719, Precision: 0.8893, Recall: 0.8517, MCC: 0.7442\n",
            "Epoch 31/500\n",
            "Train - Loss: 0.3332, Acc: 0.9472, F1: 0.9472, AUC: 0.9479, Precision: 0.9741, Recall: 0.9218, MCC: 0.8959\n",
            "Val   - Loss: 0.5043, Acc: 0.8524, F1: 0.8434, AUC: 0.8529, Precision: 0.9070, Recall: 0.7881, MCC: 0.7113\n",
            "Epoch 32/500\n",
            "Train - Loss: 0.3327, Acc: 0.9480, F1: 0.9481, AUC: 0.9486, Precision: 0.9723, Recall: 0.9250, MCC: 0.8971\n",
            "Val   - Loss: 0.5372, Acc: 0.8631, F1: 0.8603, AUC: 0.8633, Precision: 0.8862, Recall: 0.8358, MCC: 0.7274\n",
            "Epoch 33/500\n",
            "Train - Loss: 0.3248, Acc: 0.9531, F1: 0.9530, AUC: 0.9538, Precision: 0.9807, Recall: 0.9268, MCC: 0.9076\n",
            "Val   - Loss: 0.5560, Acc: 0.8584, F1: 0.8538, AUC: 0.8587, Precision: 0.8906, Recall: 0.8199, MCC: 0.7193\n",
            "Epoch 34/500\n",
            "Train - Loss: 0.3229, Acc: 0.9548, F1: 0.9547, AUC: 0.9556, Precision: 0.9843, Recall: 0.9268, MCC: 0.9113\n",
            "Val   - Loss: 0.5142, Acc: 0.8577, F1: 0.8532, AUC: 0.8580, Precision: 0.8894, Recall: 0.8199, MCC: 0.7178\n",
            "Epoch 35/500\n",
            "Train - Loss: 0.3270, Acc: 0.9531, F1: 0.9531, AUC: 0.9537, Precision: 0.9791, Recall: 0.9285, MCC: 0.9075\n",
            "Val   - Loss: 0.5744, Acc: 0.8544, F1: 0.8577, AUC: 0.8542, Precision: 0.8456, Recall: 0.8702, MCC: 0.7090\n",
            "Epoch 36/500\n",
            "Train - Loss: 0.3236, Acc: 0.9559, F1: 0.9561, AUC: 0.9565, Precision: 0.9790, Recall: 0.9341, MCC: 0.9128\n",
            "Val   - Loss: 0.5454, Acc: 0.8464, F1: 0.8385, AUC: 0.8468, Precision: 0.8924, Recall: 0.7907, MCC: 0.6976\n",
            "Epoch 37/500\n",
            "Train - Loss: 0.3300, Acc: 0.9487, F1: 0.9484, AUC: 0.9496, Precision: 0.9812, Recall: 0.9177, MCC: 0.8995\n",
            "Val   - Loss: 0.5413, Acc: 0.8410, F1: 0.8314, AUC: 0.8416, Precision: 0.8935, Recall: 0.7775, MCC: 0.6883\n",
            "Epoch 38/500\n",
            "Train - Loss: 0.3205, Acc: 0.9568, F1: 0.9570, AUC: 0.9574, Precision: 0.9799, Recall: 0.9351, MCC: 0.9147\n",
            "Val   - Loss: 0.8652, Acc: 0.8150, F1: 0.8383, AUC: 0.8138, Precision: 0.7495, Recall: 0.9510, MCC: 0.6536\n",
            "Epoch 39/500\n",
            "Train - Loss: 0.3171, Acc: 0.9603, F1: 0.9604, AUC: 0.9610, Precision: 0.9866, Recall: 0.9354, MCC: 0.9220\n",
            "Val   - Loss: 0.6464, Acc: 0.8403, F1: 0.8492, AUC: 0.8399, Precision: 0.8108, Recall: 0.8914, MCC: 0.6838\n",
            "Epoch 40/500\n",
            "Train - Loss: 0.3164, Acc: 0.9608, F1: 0.9610, AUC: 0.9615, Precision: 0.9845, Recall: 0.9385, MCC: 0.9227\n",
            "Val   - Loss: 0.7089, Acc: 0.8383, F1: 0.8463, AUC: 0.8380, Precision: 0.8132, Recall: 0.8821, MCC: 0.6789\n",
            "Epoch 41/500\n",
            "Train - Loss: 0.4305, Acc: 0.8815, F1: 0.8815, AUC: 0.8821, Precision: 0.9061, Recall: 0.8582, MCC: 0.7642\n",
            "Val   - Loss: 0.4839, Acc: 0.8330, F1: 0.8132, AUC: 0.8340, Precision: 0.9331, Recall: 0.7205, MCC: 0.6849\n",
            "Epoch 42/500\n",
            "Train - Loss: 0.3526, Acc: 0.9358, F1: 0.9360, AUC: 0.9364, Precision: 0.9587, Recall: 0.9143, MCC: 0.8726\n",
            "Val   - Loss: 0.5380, Acc: 0.8577, F1: 0.8621, AUC: 0.8575, Precision: 0.8430, Recall: 0.8821, MCC: 0.7161\n",
            "Epoch 43/500\n",
            "Train - Loss: 0.3412, Acc: 0.9409, F1: 0.9408, AUC: 0.9416, Precision: 0.9682, Recall: 0.9150, MCC: 0.8832\n",
            "Val   - Loss: 0.5032, Acc: 0.8417, F1: 0.8286, AUC: 0.8424, Precision: 0.9124, Recall: 0.7589, MCC: 0.6938\n",
            "Epoch 44/500\n",
            "Train - Loss: 0.3222, Acc: 0.9570, F1: 0.9571, AUC: 0.9576, Precision: 0.9815, Recall: 0.9338, MCC: 0.9152\n",
            "Val   - Loss: 0.5530, Acc: 0.8537, F1: 0.8525, AUC: 0.8538, Precision: 0.8671, Recall: 0.8384, MCC: 0.7079\n",
            "Epoch 45/500\n",
            "Train - Loss: 0.3218, Acc: 0.9587, F1: 0.9587, AUC: 0.9593, Precision: 0.9839, Recall: 0.9348, MCC: 0.9186\n",
            "Val   - Loss: 0.5605, Acc: 0.8570, F1: 0.8544, AUC: 0.8573, Precision: 0.8783, Recall: 0.8318, MCC: 0.7152\n",
            "Epoch 46/500\n",
            "Train - Loss: 0.3186, Acc: 0.9602, F1: 0.9602, AUC: 0.9608, Precision: 0.9850, Recall: 0.9367, MCC: 0.9215\n",
            "Val   - Loss: 0.5241, Acc: 0.8444, F1: 0.8351, AUC: 0.8449, Precision: 0.8967, Recall: 0.7815, MCC: 0.6949\n",
            "Epoch 47/500\n",
            "Train - Loss: 0.3539, Acc: 0.9328, F1: 0.9322, AUC: 0.9338, Precision: 0.9688, Recall: 0.8982, MCC: 0.8683\n",
            "Val   - Loss: 0.5862, Acc: 0.8584, F1: 0.8653, AUC: 0.8580, Precision: 0.8315, Recall: 0.9020, MCC: 0.7192\n",
            "Epoch 48/500\n",
            "Train - Loss: 0.3201, Acc: 0.9592, F1: 0.9593, AUC: 0.9598, Precision: 0.9820, Recall: 0.9377, MCC: 0.9193\n",
            "Val   - Loss: 0.5189, Acc: 0.8651, F1: 0.8641, AUC: 0.8652, Precision: 0.8782, Recall: 0.8503, MCC: 0.7306\n",
            "Epoch 49/500\n",
            "Train - Loss: 0.3076, Acc: 0.9674, F1: 0.9676, AUC: 0.9680, Precision: 0.9890, Recall: 0.9472, MCC: 0.9358\n",
            "Val   - Loss: 0.5932, Acc: 0.8437, F1: 0.8513, AUC: 0.8433, Precision: 0.8181, Recall: 0.8874, MCC: 0.6896\n",
            "Epoch 50/500\n",
            "Train - Loss: 0.3186, Acc: 0.9630, F1: 0.9632, AUC: 0.9636, Precision: 0.9844, Recall: 0.9429, MCC: 0.9269\n",
            "Val   - Loss: 0.5207, Acc: 0.8517, F1: 0.8445, AUC: 0.8522, Precision: 0.8960, Recall: 0.7987, MCC: 0.7079\n",
            "Epoch 51/500\n",
            "Train - Loss: 0.3070, Acc: 0.9691, F1: 0.9693, AUC: 0.9696, Precision: 0.9897, Recall: 0.9498, MCC: 0.9390\n",
            "Val   - Loss: 0.5675, Acc: 0.8717, F1: 0.8760, AUC: 0.8715, Precision: 0.8550, Recall: 0.8980, MCC: 0.7443\n",
            "Epoch 52/500\n",
            "Train - Loss: 0.3574, Acc: 0.9299, F1: 0.9293, AUC: 0.9308, Precision: 0.9642, Recall: 0.8969, MCC: 0.8622\n",
            "Val   - Loss: 0.6677, Acc: 0.8303, F1: 0.8449, AUC: 0.8296, Precision: 0.7837, Recall: 0.9166, MCC: 0.6700\n",
            "Epoch 53/500\n",
            "Train - Loss: 0.3130, Acc: 0.9658, F1: 0.9659, AUC: 0.9663, Precision: 0.9878, Recall: 0.9450, MCC: 0.9325\n",
            "Val   - Loss: 0.4905, Acc: 0.8537, F1: 0.8493, AUC: 0.8540, Precision: 0.8840, Recall: 0.8172, MCC: 0.7096\n",
            "Epoch 54/500\n",
            "Train - Loss: 0.3165, Acc: 0.9633, F1: 0.9636, AUC: 0.9638, Precision: 0.9818, Recall: 0.9462, MCC: 0.9273\n",
            "Val   - Loss: 0.5683, Acc: 0.8691, F1: 0.8695, AUC: 0.8691, Precision: 0.8742, Recall: 0.8649, MCC: 0.7382\n",
            "Epoch 55/500\n",
            "Train - Loss: 0.3123, Acc: 0.9662, F1: 0.9664, AUC: 0.9667, Precision: 0.9878, Recall: 0.9459, MCC: 0.9333\n",
            "Val   - Loss: 0.5788, Acc: 0.8557, F1: 0.8614, AUC: 0.8554, Precision: 0.8356, Recall: 0.8887, MCC: 0.7127\n",
            "Epoch 56/500\n",
            "Train - Loss: 0.3119, Acc: 0.9666, F1: 0.9668, AUC: 0.9671, Precision: 0.9873, Recall: 0.9472, MCC: 0.9340\n",
            "Val   - Loss: 0.5575, Acc: 0.8617, F1: 0.8600, AUC: 0.8619, Precision: 0.8785, Recall: 0.8424, MCC: 0.7241\n",
            "Epoch 57/500\n",
            "Train - Loss: 0.3046, Acc: 0.9715, F1: 0.9717, AUC: 0.9721, Precision: 0.9917, Recall: 0.9525, MCC: 0.9438\n",
            "Val   - Loss: 0.5128, Acc: 0.8470, F1: 0.8349, AUC: 0.8477, Precision: 0.9161, Recall: 0.7669, MCC: 0.7040\n",
            "Epoch 58/500\n",
            "Train - Loss: 0.3043, Acc: 0.9724, F1: 0.9726, AUC: 0.9730, Precision: 0.9936, Recall: 0.9525, MCC: 0.9457\n",
            "Val   - Loss: 0.6611, Acc: 0.8510, F1: 0.8512, AUC: 0.8511, Precision: 0.8575, Recall: 0.8450, MCC: 0.7022\n",
            "Epoch 59/500\n",
            "Train - Loss: 0.3062, Acc: 0.9704, F1: 0.9707, AUC: 0.9709, Precision: 0.9895, Recall: 0.9525, MCC: 0.9416\n",
            "Val   - Loss: 0.5681, Acc: 0.8604, F1: 0.8604, AUC: 0.8605, Precision: 0.8679, Recall: 0.8530, MCC: 0.7209\n",
            "Epoch 60/500\n",
            "Train - Loss: 0.3030, Acc: 0.9731, F1: 0.9733, AUC: 0.9736, Precision: 0.9924, Recall: 0.9550, MCC: 0.9469\n",
            "Val   - Loss: 0.5256, Acc: 0.8497, F1: 0.8430, AUC: 0.8501, Precision: 0.8909, Recall: 0.8000, MCC: 0.7034\n",
            "Epoch 61/500\n",
            "Train - Loss: 0.3010, Acc: 0.9734, F1: 0.9736, AUC: 0.9740, Precision: 0.9939, Recall: 0.9541, MCC: 0.9477\n",
            "Val   - Loss: 0.5297, Acc: 0.8584, F1: 0.8568, AUC: 0.8585, Precision: 0.8745, Recall: 0.8397, MCC: 0.7174\n",
            "Epoch 62/500\n",
            "Train - Loss: 0.3065, Acc: 0.9707, F1: 0.9709, AUC: 0.9712, Precision: 0.9907, Recall: 0.9519, MCC: 0.9421\n",
            "Val   - Loss: 0.6477, Acc: 0.8410, F1: 0.8434, AUC: 0.8409, Precision: 0.8379, Recall: 0.8490, MCC: 0.6820\n",
            "Epoch 63/500\n",
            "Train - Loss: 0.3479, Acc: 0.9429, F1: 0.9430, AUC: 0.9436, Precision: 0.9688, Recall: 0.9185, MCC: 0.8872\n",
            "Val   - Loss: 0.5540, Acc: 0.8557, F1: 0.8568, AUC: 0.8557, Precision: 0.8579, Recall: 0.8556, MCC: 0.7114\n",
            "Epoch 64/500\n",
            "Train - Loss: 0.3067, Acc: 0.9710, F1: 0.9713, AUC: 0.9715, Precision: 0.9895, Recall: 0.9537, MCC: 0.9427\n",
            "Val   - Loss: 0.5497, Acc: 0.8644, F1: 0.8664, AUC: 0.8643, Precision: 0.8613, Recall: 0.8715, MCC: 0.7288\n",
            "Epoch 65/500\n",
            "Train - Loss: 0.3076, Acc: 0.9703, F1: 0.9706, AUC: 0.9709, Precision: 0.9895, Recall: 0.9524, MCC: 0.9414\n",
            "Val   - Loss: 0.5615, Acc: 0.8664, F1: 0.8681, AUC: 0.8664, Precision: 0.8647, Recall: 0.8715, MCC: 0.7328\n",
            "Epoch 66/500\n",
            "Train - Loss: 0.3012, Acc: 0.9750, F1: 0.9753, AUC: 0.9755, Precision: 0.9921, Recall: 0.9590, MCC: 0.9506\n",
            "Val   - Loss: 0.6018, Acc: 0.8591, F1: 0.8618, AUC: 0.8589, Precision: 0.8523, Recall: 0.8715, MCC: 0.7182\n",
            "Epoch 67/500\n",
            "Train - Loss: 0.3073, Acc: 0.9691, F1: 0.9693, AUC: 0.9696, Precision: 0.9893, Recall: 0.9501, MCC: 0.9390\n",
            "Val   - Loss: 0.5463, Acc: 0.8617, F1: 0.8593, AUC: 0.8619, Precision: 0.8827, Recall: 0.8371, MCC: 0.7245\n",
            "Epoch 68/500\n",
            "Train - Loss: 0.3040, Acc: 0.9730, F1: 0.9733, AUC: 0.9735, Precision: 0.9914, Recall: 0.9558, MCC: 0.9467\n",
            "Val   - Loss: 0.5030, Acc: 0.8617, F1: 0.8543, AUC: 0.8622, Precision: 0.9114, Recall: 0.8040, MCC: 0.7289\n",
            "Epoch 69/500\n",
            "Train - Loss: 0.2991, Acc: 0.9761, F1: 0.9763, AUC: 0.9766, Precision: 0.9939, Recall: 0.9593, MCC: 0.9528\n",
            "Val   - Loss: 0.5511, Acc: 0.8577, F1: 0.8524, AUC: 0.8581, Precision: 0.8939, Recall: 0.8146, MCC: 0.7185\n",
            "Epoch 70/500\n",
            "Train - Loss: 0.3014, Acc: 0.9734, F1: 0.9735, AUC: 0.9739, Precision: 0.9937, Recall: 0.9541, MCC: 0.9475\n",
            "Val   - Loss: 0.5611, Acc: 0.8664, F1: 0.8647, AUC: 0.8666, Precision: 0.8838, Recall: 0.8464, MCC: 0.7335\n",
            "Epoch 71/500\n",
            "Train - Loss: 0.3016, Acc: 0.9748, F1: 0.9750, AUC: 0.9752, Precision: 0.9916, Recall: 0.9590, MCC: 0.9501\n",
            "Val   - Loss: 0.5805, Acc: 0.8711, F1: 0.8733, AUC: 0.8710, Precision: 0.8659, Recall: 0.8808, MCC: 0.7422\n",
            "Epoch 72/500\n",
            "Train - Loss: 0.2996, Acc: 0.9741, F1: 0.9743, AUC: 0.9746, Precision: 0.9944, Recall: 0.9550, MCC: 0.9490\n",
            "Val   - Loss: 0.5291, Acc: 0.8644, F1: 0.8646, AUC: 0.8644, Precision: 0.8710, Recall: 0.8583, MCC: 0.7289\n",
            "Epoch 73/500\n",
            "Train - Loss: 0.3035, Acc: 0.9718, F1: 0.9721, AUC: 0.9723, Precision: 0.9907, Recall: 0.9541, MCC: 0.9444\n",
            "Val   - Loss: 0.5680, Acc: 0.8664, F1: 0.8652, AUC: 0.8665, Precision: 0.8807, Recall: 0.8503, MCC: 0.7333\n",
            "Epoch 74/500\n",
            "Train - Loss: 0.3006, Acc: 0.9754, F1: 0.9756, AUC: 0.9758, Precision: 0.9926, Recall: 0.9592, MCC: 0.9513\n",
            "Val   - Loss: 0.6024, Acc: 0.8671, F1: 0.8678, AUC: 0.8671, Precision: 0.8707, Recall: 0.8649, MCC: 0.7341\n",
            "Epoch 75/500\n",
            "Train - Loss: 0.2976, Acc: 0.9774, F1: 0.9777, AUC: 0.9779, Precision: 0.9953, Recall: 0.9607, MCC: 0.9555\n",
            "Val   - Loss: 0.5456, Acc: 0.8497, F1: 0.8456, AUC: 0.8500, Precision: 0.8775, Recall: 0.8159, MCC: 0.7013\n",
            "Epoch 76/500\n",
            "Train - Loss: 0.3021, Acc: 0.9742, F1: 0.9744, AUC: 0.9747, Precision: 0.9919, Recall: 0.9576, MCC: 0.9490\n",
            "Val   - Loss: 0.6094, Acc: 0.8591, F1: 0.8622, AUC: 0.8589, Precision: 0.8505, Recall: 0.8742, MCC: 0.7183\n",
            "Epoch 77/500\n",
            "Train - Loss: 0.3116, Acc: 0.9667, F1: 0.9670, AUC: 0.9672, Precision: 0.9850, Recall: 0.9496, MCC: 0.9340\n",
            "Val   - Loss: 0.5092, Acc: 0.8564, F1: 0.8491, AUC: 0.8569, Precision: 0.9030, Recall: 0.8013, MCC: 0.7177\n",
            "Epoch 78/500\n",
            "Train - Loss: 0.2974, Acc: 0.9775, F1: 0.9778, AUC: 0.9780, Precision: 0.9935, Recall: 0.9626, MCC: 0.9556\n",
            "Val   - Loss: 0.5679, Acc: 0.8557, F1: 0.8500, AUC: 0.8561, Precision: 0.8934, Recall: 0.8106, MCC: 0.7148\n",
            "Epoch 79/500\n",
            "Train - Loss: 0.2977, Acc: 0.9774, F1: 0.9776, AUC: 0.9778, Precision: 0.9935, Recall: 0.9623, MCC: 0.9552\n",
            "Val   - Loss: 0.6969, Acc: 0.8651, F1: 0.8703, AUC: 0.8648, Precision: 0.8443, Recall: 0.8980, MCC: 0.7315\n",
            "Epoch 80/500\n",
            "Train - Loss: 0.3007, Acc: 0.9759, F1: 0.9761, AUC: 0.9763, Precision: 0.9918, Recall: 0.9610, MCC: 0.9522\n",
            "Val   - Loss: 0.6680, Acc: 0.8631, F1: 0.8687, AUC: 0.8628, Precision: 0.8412, Recall: 0.8980, MCC: 0.7276\n",
            "Epoch 81/500\n",
            "Train - Loss: 0.2979, Acc: 0.9781, F1: 0.9784, AUC: 0.9785, Precision: 0.9938, Recall: 0.9634, MCC: 0.9567\n",
            "Val   - Loss: 0.5306, Acc: 0.8243, F1: 0.8045, AUC: 0.8253, Precision: 0.9169, Recall: 0.7166, MCC: 0.6656\n",
            "Epoch 82/500\n",
            "Train - Loss: 0.3278, Acc: 0.9566, F1: 0.9570, AUC: 0.9570, Precision: 0.9726, Recall: 0.9420, MCC: 0.9136\n",
            "Val   - Loss: 0.5403, Acc: 0.8403, F1: 0.8369, AUC: 0.8406, Precision: 0.8634, Recall: 0.8119, MCC: 0.6821\n",
            "Epoch 83/500\n",
            "Train - Loss: 0.2999, Acc: 0.9774, F1: 0.9777, AUC: 0.9778, Precision: 0.9925, Recall: 0.9634, MCC: 0.9553\n",
            "Val   - Loss: 0.5874, Acc: 0.8550, F1: 0.8581, AUC: 0.8549, Precision: 0.8475, Recall: 0.8689, MCC: 0.7102\n",
            "Epoch 84/500\n",
            "Train - Loss: 0.2958, Acc: 0.9795, F1: 0.9797, AUC: 0.9798, Precision: 0.9938, Recall: 0.9660, MCC: 0.9593\n",
            "Val   - Loss: 0.5691, Acc: 0.8597, F1: 0.8579, AUC: 0.8599, Precision: 0.8769, Recall: 0.8397, MCC: 0.7202\n",
            "Epoch 85/500\n",
            "Train - Loss: 0.2987, Acc: 0.9774, F1: 0.9776, AUC: 0.9778, Precision: 0.9931, Recall: 0.9626, MCC: 0.9552\n",
            "Val   - Loss: 0.6087, Acc: 0.8564, F1: 0.8571, AUC: 0.8564, Precision: 0.8600, Recall: 0.8543, MCC: 0.7128\n",
            "Epoch 86/500\n",
            "Train - Loss: 0.2950, Acc: 0.9800, F1: 0.9803, AUC: 0.9804, Precision: 0.9945, Recall: 0.9665, MCC: 0.9605\n",
            "Val   - Loss: 0.6747, Acc: 0.8530, F1: 0.8564, AUC: 0.8529, Precision: 0.8443, Recall: 0.8689, MCC: 0.7063\n",
            "Epoch 87/500\n",
            "Train - Loss: 0.2973, Acc: 0.9791, F1: 0.9794, AUC: 0.9795, Precision: 0.9938, Recall: 0.9654, MCC: 0.9586\n",
            "Val   - Loss: 0.5444, Acc: 0.8550, F1: 0.8498, AUC: 0.8554, Precision: 0.8899, Recall: 0.8132, MCC: 0.7130\n",
            "Epoch 88/500\n",
            "Train - Loss: 0.2956, Acc: 0.9791, F1: 0.9793, AUC: 0.9796, Precision: 0.9960, Recall: 0.9633, MCC: 0.9588\n",
            "Val   - Loss: 0.6374, Acc: 0.8631, F1: 0.8673, AUC: 0.8628, Precision: 0.8481, Recall: 0.8874, MCC: 0.7268\n",
            "Epoch 89/500\n",
            "Train - Loss: 0.3243, Acc: 0.9603, F1: 0.9607, AUC: 0.9608, Precision: 0.9771, Recall: 0.9449, MCC: 0.9212\n",
            "Val   - Loss: 0.6019, Acc: 0.8597, F1: 0.8618, AUC: 0.8597, Precision: 0.8562, Recall: 0.8675, MCC: 0.7194\n",
            "Epoch 90/500\n",
            "Train - Loss: 0.2966, Acc: 0.9795, F1: 0.9797, AUC: 0.9798, Precision: 0.9938, Recall: 0.9660, MCC: 0.9593\n",
            "Val   - Loss: 0.7280, Acc: 0.8270, F1: 0.8435, AUC: 0.8261, Precision: 0.7756, Recall: 0.9245, MCC: 0.6660\n",
            "Epoch 91/500\n",
            "Train - Loss: 0.3365, Acc: 0.9496, F1: 0.9503, AUC: 0.9500, Precision: 0.9645, Recall: 0.9364, MCC: 0.8997\n",
            "Val   - Loss: 0.5311, Acc: 0.8564, F1: 0.8534, AUC: 0.8566, Precision: 0.8792, Recall: 0.8291, MCC: 0.7141\n",
            "Epoch 92/500\n",
            "Train - Loss: 0.3002, Acc: 0.9753, F1: 0.9756, AUC: 0.9757, Precision: 0.9909, Recall: 0.9607, MCC: 0.9510\n",
            "Val   - Loss: 0.5264, Acc: 0.8651, F1: 0.8642, AUC: 0.8652, Precision: 0.8772, Recall: 0.8517, MCC: 0.7305\n",
            "Epoch 93/500\n",
            "Train - Loss: 0.2961, Acc: 0.9800, F1: 0.9802, AUC: 0.9803, Precision: 0.9935, Recall: 0.9673, MCC: 0.9603\n",
            "Val   - Loss: 0.5878, Acc: 0.8564, F1: 0.8585, AUC: 0.8563, Precision: 0.8534, Recall: 0.8636, MCC: 0.7128\n",
            "Epoch 94/500\n",
            "Train - Loss: 0.2912, Acc: 0.9823, F1: 0.9825, AUC: 0.9827, Precision: 0.9967, Recall: 0.9688, MCC: 0.9650\n",
            "Val   - Loss: 0.5885, Acc: 0.8550, F1: 0.8531, AUC: 0.8552, Precision: 0.8726, Recall: 0.8344, MCC: 0.7109\n",
            "Epoch 95/500\n",
            "Train - Loss: 0.2942, Acc: 0.9799, F1: 0.9801, AUC: 0.9803, Precision: 0.9950, Recall: 0.9657, MCC: 0.9602\n",
            "Val   - Loss: 0.5719, Acc: 0.8550, F1: 0.8525, AUC: 0.8553, Precision: 0.8757, Recall: 0.8305, MCC: 0.7112\n",
            "Epoch 96/500\n",
            "Train - Loss: 0.2961, Acc: 0.9788, F1: 0.9790, AUC: 0.9792, Precision: 0.9941, Recall: 0.9644, MCC: 0.9580\n",
            "Val   - Loss: 0.6439, Acc: 0.8544, F1: 0.8632, AUC: 0.8539, Precision: 0.8200, Recall: 0.9113, MCC: 0.7130\n",
            "Epoch 97/500\n",
            "Train - Loss: 0.3078, Acc: 0.9718, F1: 0.9721, AUC: 0.9721, Precision: 0.9864, Recall: 0.9582, MCC: 0.9439\n",
            "Val   - Loss: 0.5757, Acc: 0.8677, F1: 0.8678, AUC: 0.8678, Precision: 0.8748, Recall: 0.8609, MCC: 0.7356\n",
            "Epoch 98/500\n",
            "Train - Loss: 0.2925, Acc: 0.9818, F1: 0.9820, AUC: 0.9822, Precision: 0.9960, Recall: 0.9685, MCC: 0.9640\n",
            "Val   - Loss: 0.5810, Acc: 0.8751, F1: 0.8754, AUC: 0.8751, Precision: 0.8807, Recall: 0.8702, MCC: 0.7502\n",
            "Epoch 99/500\n",
            "Train - Loss: 0.2904, Acc: 0.9838, F1: 0.9840, AUC: 0.9842, Precision: 0.9973, Recall: 0.9711, MCC: 0.9679\n",
            "Val   - Loss: 0.5299, Acc: 0.8450, F1: 0.8329, AUC: 0.8457, Precision: 0.9131, Recall: 0.7656, MCC: 0.6998\n",
            "Epoch 100/500\n",
            "Train - Loss: 0.3284, Acc: 0.9566, F1: 0.9569, AUC: 0.9572, Precision: 0.9771, Recall: 0.9376, MCC: 0.9141\n",
            "Val   - Loss: 0.5190, Acc: 0.8697, F1: 0.8669, AUC: 0.8700, Precision: 0.8944, Recall: 0.8411, MCC: 0.7409\n",
            "Epoch 101/500\n",
            "Train - Loss: 0.2931, Acc: 0.9815, F1: 0.9817, AUC: 0.9818, Precision: 0.9955, Recall: 0.9683, MCC: 0.9633\n",
            "Val   - Loss: 0.5879, Acc: 0.8544, F1: 0.8543, AUC: 0.8544, Precision: 0.8623, Recall: 0.8464, MCC: 0.7089\n",
            "Epoch 102/500\n",
            "Train - Loss: 0.2912, Acc: 0.9825, F1: 0.9827, AUC: 0.9828, Precision: 0.9960, Recall: 0.9698, MCC: 0.9653\n",
            "Val   - Loss: 0.6051, Acc: 0.8611, F1: 0.8619, AUC: 0.8611, Precision: 0.8642, Recall: 0.8596, MCC: 0.7221\n",
            "Epoch 103/500\n",
            "Train - Loss: 0.2913, Acc: 0.9824, F1: 0.9826, AUC: 0.9827, Precision: 0.9963, Recall: 0.9693, MCC: 0.9651\n",
            "Val   - Loss: 0.7128, Acc: 0.8464, F1: 0.8529, AUC: 0.8460, Precision: 0.8245, Recall: 0.8834, MCC: 0.6943\n",
            "Epoch 104/500\n",
            "Train - Loss: 0.3497, Acc: 0.9394, F1: 0.9394, AUC: 0.9402, Precision: 0.9673, Recall: 0.9130, MCC: 0.8804\n",
            "Val   - Loss: 0.5334, Acc: 0.8504, F1: 0.8420, AUC: 0.8509, Precision: 0.9005, Recall: 0.7907, MCC: 0.7064\n",
            "Epoch 105/500\n",
            "Train - Loss: 0.3007, Acc: 0.9760, F1: 0.9763, AUC: 0.9764, Precision: 0.9910, Recall: 0.9621, MCC: 0.9525\n",
            "Val   - Loss: 0.5879, Acc: 0.8537, F1: 0.8521, AUC: 0.8539, Precision: 0.8691, Recall: 0.8358, MCC: 0.7080\n",
            "Epoch 106/500\n",
            "Train - Loss: 0.2941, Acc: 0.9814, F1: 0.9816, AUC: 0.9818, Precision: 0.9957, Recall: 0.9680, MCC: 0.9631\n",
            "Val   - Loss: 0.7385, Acc: 0.8477, F1: 0.8577, AUC: 0.8472, Precision: 0.8111, Recall: 0.9099, MCC: 0.7004\n",
            "Epoch 107/500\n",
            "Train - Loss: 0.2946, Acc: 0.9805, F1: 0.9808, AUC: 0.9809, Precision: 0.9942, Recall: 0.9678, MCC: 0.9614\n",
            "Val   - Loss: 0.5835, Acc: 0.8624, F1: 0.8668, AUC: 0.8622, Precision: 0.8470, Recall: 0.8874, MCC: 0.7255\n",
            "Epoch 108/500\n",
            "Train - Loss: 0.3034, Acc: 0.9745, F1: 0.9748, AUC: 0.9750, Precision: 0.9913, Recall: 0.9589, MCC: 0.9496\n",
            "Val   - Loss: 0.5407, Acc: 0.8510, F1: 0.8450, AUC: 0.8514, Precision: 0.8889, Recall: 0.8053, MCC: 0.7055\n",
            "Epoch 109/500\n",
            "Train - Loss: 0.2930, Acc: 0.9826, F1: 0.9829, AUC: 0.9829, Precision: 0.9948, Recall: 0.9712, MCC: 0.9655\n",
            "Val   - Loss: 0.5695, Acc: 0.8570, F1: 0.8548, AUC: 0.8572, Precision: 0.8762, Recall: 0.8344, MCC: 0.7150\n",
            "Epoch 110/500\n",
            "Train - Loss: 0.2910, Acc: 0.9839, F1: 0.9841, AUC: 0.9842, Precision: 0.9963, Recall: 0.9722, MCC: 0.9681\n",
            "Val   - Loss: 0.5374, Acc: 0.8611, F1: 0.8598, AUC: 0.8612, Precision: 0.8752, Recall: 0.8450, MCC: 0.7226\n",
            "Epoch 111/500\n",
            "Train - Loss: 0.2908, Acc: 0.9838, F1: 0.9840, AUC: 0.9841, Precision: 0.9970, Recall: 0.9714, MCC: 0.9679\n",
            "Val   - Loss: 0.6089, Acc: 0.8524, F1: 0.8549, AUC: 0.8523, Precision: 0.8477, Recall: 0.8623, MCC: 0.7048\n",
            "Epoch 112/500\n",
            "Train - Loss: 0.2927, Acc: 0.9826, F1: 0.9829, AUC: 0.9829, Precision: 0.9943, Recall: 0.9717, MCC: 0.9655\n",
            "Val   - Loss: 0.7795, Acc: 0.8490, F1: 0.8603, AUC: 0.8484, Precision: 0.8065, Recall: 0.9219, MCC: 0.7051\n",
            "Epoch 113/500\n",
            "Train - Loss: 0.3672, Acc: 0.9263, F1: 0.9253, AUC: 0.9274, Precision: 0.9662, Recall: 0.8876, MCC: 0.8559\n",
            "Val   - Loss: 0.5672, Acc: 0.8537, F1: 0.8549, AUC: 0.8537, Precision: 0.8554, Recall: 0.8543, MCC: 0.7074\n",
            "Epoch 114/500\n",
            "Train - Loss: 0.3086, Acc: 0.9723, F1: 0.9727, AUC: 0.9726, Precision: 0.9848, Recall: 0.9608, MCC: 0.9448\n",
            "Val   - Loss: 0.5497, Acc: 0.8477, F1: 0.8459, AUC: 0.8479, Precision: 0.8634, Recall: 0.8291, MCC: 0.6960\n",
            "Epoch 115/500\n",
            "Train - Loss: 0.3018, Acc: 0.9759, F1: 0.9763, AUC: 0.9763, Precision: 0.9888, Recall: 0.9641, MCC: 0.9522\n",
            "Val   - Loss: 0.5574, Acc: 0.8537, F1: 0.8482, AUC: 0.8541, Precision: 0.8895, Recall: 0.8106, MCC: 0.7105\n",
            "Epoch 116/500\n",
            "Train - Loss: 0.3005, Acc: 0.9756, F1: 0.9759, AUC: 0.9760, Precision: 0.9901, Recall: 0.9621, MCC: 0.9516\n",
            "Val   - Loss: 0.5860, Acc: 0.8591, F1: 0.8596, AUC: 0.8591, Precision: 0.8636, Recall: 0.8556, MCC: 0.7181\n",
            "Epoch 117/500\n",
            "Train - Loss: 0.2923, Acc: 0.9824, F1: 0.9826, AUC: 0.9828, Precision: 0.9968, Recall: 0.9688, MCC: 0.9652\n",
            "Val   - Loss: 0.5380, Acc: 0.8504, F1: 0.8436, AUC: 0.8508, Precision: 0.8922, Recall: 0.8000, MCC: 0.7048\n",
            "Epoch 118/500\n",
            "Train - Loss: 0.2937, Acc: 0.9820, F1: 0.9822, AUC: 0.9823, Precision: 0.9957, Recall: 0.9691, MCC: 0.9643\n",
            "Val   - Loss: 0.5878, Acc: 0.8497, F1: 0.8513, AUC: 0.8497, Precision: 0.8496, Recall: 0.8530, MCC: 0.6994\n",
            "Epoch 119/500\n",
            "Train - Loss: 0.2910, Acc: 0.9830, F1: 0.9833, AUC: 0.9834, Precision: 0.9967, Recall: 0.9702, MCC: 0.9664\n",
            "Val   - Loss: 0.6307, Acc: 0.8544, F1: 0.8564, AUC: 0.8543, Precision: 0.8519, Recall: 0.8609, MCC: 0.7087\n",
            "Epoch 120/500\n",
            "Train - Loss: 0.2920, Acc: 0.9824, F1: 0.9826, AUC: 0.9828, Precision: 0.9968, Recall: 0.9688, MCC: 0.9652\n",
            "Val   - Loss: 0.5910, Acc: 0.8464, F1: 0.8446, AUC: 0.8465, Precision: 0.8621, Recall: 0.8278, MCC: 0.6934\n",
            "Epoch 121/500\n",
            "Train - Loss: 0.2930, Acc: 0.9827, F1: 0.9830, AUC: 0.9830, Precision: 0.9952, Recall: 0.9711, MCC: 0.9657\n",
            "Val   - Loss: 0.5902, Acc: 0.8524, F1: 0.8494, AUC: 0.8526, Precision: 0.8750, Recall: 0.8252, MCC: 0.7060\n",
            "Epoch 122/500\n",
            "Train - Loss: 0.2923, Acc: 0.9839, F1: 0.9841, AUC: 0.9842, Precision: 0.9967, Recall: 0.9719, MCC: 0.9681\n",
            "Val   - Loss: 0.5717, Acc: 0.8611, F1: 0.8642, AUC: 0.8609, Precision: 0.8520, Recall: 0.8768, MCC: 0.7223\n",
            "Epoch 123/500\n",
            "Train - Loss: 0.2883, Acc: 0.9852, F1: 0.9854, AUC: 0.9856, Precision: 0.9980, Recall: 0.9732, MCC: 0.9707\n",
            "Val   - Loss: 0.7943, Acc: 0.8437, F1: 0.8484, AUC: 0.8435, Precision: 0.8302, Recall: 0.8675, MCC: 0.6879\n",
            "Epoch 124/500\n",
            "Train - Loss: 0.3240, Acc: 0.9618, F1: 0.9621, AUC: 0.9623, Precision: 0.9806, Recall: 0.9444, MCC: 0.9243\n",
            "Val   - Loss: 0.5726, Acc: 0.8550, F1: 0.8519, AUC: 0.8553, Precision: 0.8789, Recall: 0.8265, MCC: 0.7115\n",
            "Epoch 125/500\n",
            "Train - Loss: 0.2956, Acc: 0.9808, F1: 0.9811, AUC: 0.9811, Precision: 0.9943, Recall: 0.9681, MCC: 0.9619\n",
            "Val   - Loss: 0.7207, Acc: 0.8557, F1: 0.8631, AUC: 0.8553, Precision: 0.8275, Recall: 0.9020, MCC: 0.7141\n",
            "Epoch 126/500\n",
            "Train - Loss: 0.2929, Acc: 0.9824, F1: 0.9826, AUC: 0.9827, Precision: 0.9952, Recall: 0.9704, MCC: 0.9651\n",
            "Val   - Loss: 0.6006, Acc: 0.8570, F1: 0.8538, AUC: 0.8573, Precision: 0.8815, Recall: 0.8278, MCC: 0.7156\n",
            "Epoch 127/500\n",
            "Train - Loss: 0.2899, Acc: 0.9845, F1: 0.9847, AUC: 0.9848, Precision: 0.9970, Recall: 0.9727, MCC: 0.9692\n",
            "Val   - Loss: 0.6377, Acc: 0.8570, F1: 0.8542, AUC: 0.8573, Precision: 0.8794, Recall: 0.8305, MCC: 0.7153\n",
            "Epoch 128/500\n",
            "Train - Loss: 0.3296, Acc: 0.9558, F1: 0.9561, AUC: 0.9563, Precision: 0.9758, Recall: 0.9372, MCC: 0.9124\n",
            "Val   - Loss: 0.5241, Acc: 0.8337, F1: 0.8220, AUC: 0.8343, Precision: 0.8929, Recall: 0.7616, MCC: 0.6752\n",
            "Epoch 129/500\n",
            "Train - Loss: 0.2954, Acc: 0.9810, F1: 0.9813, AUC: 0.9814, Precision: 0.9942, Recall: 0.9688, MCC: 0.9624\n",
            "Val   - Loss: 0.5863, Acc: 0.8497, F1: 0.8507, AUC: 0.8497, Precision: 0.8524, Recall: 0.8490, MCC: 0.6994\n",
            "Epoch 130/500\n",
            "Train - Loss: 0.2920, Acc: 0.9834, F1: 0.9836, AUC: 0.9837, Precision: 0.9953, Recall: 0.9722, MCC: 0.9670\n",
            "Val   - Loss: 0.5976, Acc: 0.8297, F1: 0.8230, AUC: 0.8300, Precision: 0.8644, Recall: 0.7854, MCC: 0.6624\n",
            "Epoch 131/500\n",
            "Train - Loss: 0.2909, Acc: 0.9840, F1: 0.9842, AUC: 0.9843, Precision: 0.9973, Recall: 0.9714, MCC: 0.9683\n",
            "Val   - Loss: 0.7091, Acc: 0.8470, F1: 0.8531, AUC: 0.8467, Precision: 0.8271, Recall: 0.8808, MCC: 0.6954\n",
            "Epoch 132/500\n",
            "Train - Loss: 0.2903, Acc: 0.9844, F1: 0.9846, AUC: 0.9847, Precision: 0.9968, Recall: 0.9727, MCC: 0.9691\n",
            "Val   - Loss: 0.6865, Acc: 0.8604, F1: 0.8633, AUC: 0.8603, Precision: 0.8527, Recall: 0.8742, MCC: 0.7209\n",
            "Epoch 133/500\n",
            "Train - Loss: 0.2925, Acc: 0.9843, F1: 0.9845, AUC: 0.9846, Precision: 0.9957, Recall: 0.9737, MCC: 0.9688\n",
            "Val   - Loss: 0.6365, Acc: 0.8510, F1: 0.8514, AUC: 0.8511, Precision: 0.8566, Recall: 0.8464, MCC: 0.7021\n",
            "Epoch 134/500\n",
            "Train - Loss: 0.2935, Acc: 0.9826, F1: 0.9829, AUC: 0.9829, Precision: 0.9943, Recall: 0.9717, MCC: 0.9655\n",
            "Val   - Loss: 0.5940, Acc: 0.8631, F1: 0.8604, AUC: 0.8633, Precision: 0.8852, Recall: 0.8371, MCC: 0.7273\n",
            "Epoch 135/500\n",
            "Train - Loss: 0.2900, Acc: 0.9848, F1: 0.9850, AUC: 0.9851, Precision: 0.9977, Recall: 0.9727, MCC: 0.9699\n",
            "Val   - Loss: 0.5770, Acc: 0.8597, F1: 0.8607, AUC: 0.8597, Precision: 0.8619, Recall: 0.8596, MCC: 0.7194\n",
            "Epoch 136/500\n",
            "Train - Loss: 0.2923, Acc: 0.9827, F1: 0.9830, AUC: 0.9830, Precision: 0.9942, Recall: 0.9720, MCC: 0.9657\n",
            "Val   - Loss: 0.5503, Acc: 0.8577, F1: 0.8550, AUC: 0.8579, Precision: 0.8796, Recall: 0.8318, MCC: 0.7166\n",
            "Epoch 137/500\n",
            "Train - Loss: 0.2907, Acc: 0.9844, F1: 0.9846, AUC: 0.9847, Precision: 0.9970, Recall: 0.9725, MCC: 0.9691\n",
            "Val   - Loss: 0.6995, Acc: 0.8450, F1: 0.8519, AUC: 0.8447, Precision: 0.8224, Recall: 0.8834, MCC: 0.6918\n",
            "Epoch 138/500\n",
            "Train - Loss: 0.2901, Acc: 0.9851, F1: 0.9854, AUC: 0.9854, Precision: 0.9962, Recall: 0.9748, MCC: 0.9705\n",
            "Val   - Loss: 0.6650, Acc: 0.8577, F1: 0.8625, AUC: 0.8575, Precision: 0.8413, Recall: 0.8848, MCC: 0.7163\n",
            "Epoch 139/500\n",
            "Train - Loss: 0.2950, Acc: 0.9805, F1: 0.9808, AUC: 0.9809, Precision: 0.9958, Recall: 0.9662, MCC: 0.9615\n",
            "Val   - Loss: 0.6387, Acc: 0.8564, F1: 0.8588, AUC: 0.8563, Precision: 0.8516, Recall: 0.8662, MCC: 0.7128\n",
            "Epoch 140/500\n",
            "Train - Loss: 0.2944, Acc: 0.9820, F1: 0.9822, AUC: 0.9823, Precision: 0.9948, Recall: 0.9699, MCC: 0.9642\n",
            "Val   - Loss: 0.5814, Acc: 0.8210, F1: 0.8091, AUC: 0.8216, Precision: 0.8752, Recall: 0.7523, MCC: 0.6489\n",
            "Epoch 141/500\n",
            "Train - Loss: 0.3571, Acc: 0.9347, F1: 0.9347, AUC: 0.9354, Precision: 0.9601, Recall: 0.9107, MCC: 0.8707\n",
            "Val   - Loss: 0.5321, Acc: 0.8557, F1: 0.8583, AUC: 0.8556, Precision: 0.8505, Recall: 0.8662, MCC: 0.7115\n",
            "Epoch 142/500\n",
            "Train - Loss: 0.2979, Acc: 0.9798, F1: 0.9801, AUC: 0.9801, Precision: 0.9910, Recall: 0.9694, MCC: 0.9598\n",
            "Val   - Loss: 0.5728, Acc: 0.8644, F1: 0.8686, AUC: 0.8642, Precision: 0.8494, Recall: 0.8887, MCC: 0.7295\n",
            "Epoch 143/500\n",
            "Train - Loss: 0.3084, Acc: 0.9725, F1: 0.9729, AUC: 0.9729, Precision: 0.9868, Recall: 0.9593, MCC: 0.9454\n",
            "Val   - Loss: 0.5212, Acc: 0.8484, F1: 0.8429, AUC: 0.8487, Precision: 0.8826, Recall: 0.8066, MCC: 0.6996\n",
            "Epoch 144/500\n",
            "Train - Loss: 0.2931, Acc: 0.9834, F1: 0.9836, AUC: 0.9837, Precision: 0.9955, Recall: 0.9720, MCC: 0.9670\n",
            "Val   - Loss: 0.6492, Acc: 0.8517, F1: 0.8611, AUC: 0.8512, Precision: 0.8161, Recall: 0.9113, MCC: 0.7080\n",
            "Epoch 145/500\n",
            "Train - Loss: 0.2900, Acc: 0.9854, F1: 0.9856, AUC: 0.9857, Precision: 0.9963, Recall: 0.9751, MCC: 0.9710\n",
            "Val   - Loss: 0.6185, Acc: 0.8651, F1: 0.8681, AUC: 0.8649, Precision: 0.8559, Recall: 0.8808, MCC: 0.7304\n",
            "Epoch 146/500\n",
            "Train - Loss: 0.2880, Acc: 0.9866, F1: 0.9868, AUC: 0.9869, Precision: 0.9980, Recall: 0.9759, MCC: 0.9735\n",
            "Val   - Loss: 0.6101, Acc: 0.8584, F1: 0.8609, AUC: 0.8583, Precision: 0.8531, Recall: 0.8689, MCC: 0.7168\n",
            "Epoch 147/500\n",
            "Train - Loss: 0.2922, Acc: 0.9837, F1: 0.9840, AUC: 0.9840, Precision: 0.9960, Recall: 0.9722, MCC: 0.9677\n",
            "Val   - Loss: 0.6540, Acc: 0.8557, F1: 0.8573, AUC: 0.8557, Precision: 0.8551, Recall: 0.8596, MCC: 0.7114\n",
            "Epoch 148/500\n",
            "Train - Loss: 0.2883, Acc: 0.9862, F1: 0.9864, AUC: 0.9865, Precision: 0.9977, Recall: 0.9754, MCC: 0.9727\n",
            "Val   - Loss: 0.8075, Acc: 0.8430, F1: 0.8556, AUC: 0.8423, Precision: 0.7982, Recall: 0.9219, MCC: 0.6941\n",
            "Epoch 149/500\n",
            "Train - Loss: 0.3115, Acc: 0.9691, F1: 0.9695, AUC: 0.9694, Precision: 0.9823, Recall: 0.9571, MCC: 0.9385\n",
            "Val   - Loss: 0.5348, Acc: 0.8637, F1: 0.8610, AUC: 0.8640, Precision: 0.8864, Recall: 0.8371, MCC: 0.7287\n",
            "Epoch 150/500\n",
            "Train - Loss: 0.2908, Acc: 0.9853, F1: 0.9855, AUC: 0.9856, Precision: 0.9970, Recall: 0.9743, MCC: 0.9709\n",
            "Val   - Loss: 0.5653, Acc: 0.8611, F1: 0.8575, AUC: 0.8613, Precision: 0.8879, Recall: 0.8291, MCC: 0.7239\n",
            "Epoch 151/500\n",
            "Train - Loss: 0.2891, Acc: 0.9855, F1: 0.9858, AUC: 0.9859, Precision: 0.9972, Recall: 0.9746, MCC: 0.9714\n",
            "Val   - Loss: 0.5389, Acc: 0.8450, F1: 0.8404, AUC: 0.8453, Precision: 0.8741, Recall: 0.8093, MCC: 0.6922\n",
            "Epoch 152/500\n",
            "Train - Loss: 0.2907, Acc: 0.9843, F1: 0.9845, AUC: 0.9846, Precision: 0.9960, Recall: 0.9733, MCC: 0.9689\n",
            "Val   - Loss: 0.5908, Acc: 0.8570, F1: 0.8603, AUC: 0.8569, Precision: 0.8481, Recall: 0.8728, MCC: 0.7143\n",
            "Epoch 153/500\n",
            "Train - Loss: 0.2934, Acc: 0.9831, F1: 0.9834, AUC: 0.9834, Precision: 0.9952, Recall: 0.9719, MCC: 0.9665\n",
            "Val   - Loss: 0.6196, Acc: 0.8631, F1: 0.8663, AUC: 0.8629, Precision: 0.8535, Recall: 0.8795, MCC: 0.7264\n",
            "Epoch 154/500\n",
            "Train - Loss: 0.2891, Acc: 0.9851, F1: 0.9854, AUC: 0.9854, Precision: 0.9968, Recall: 0.9741, MCC: 0.9705\n",
            "Val   - Loss: 0.6008, Acc: 0.8577, F1: 0.8552, AUC: 0.8579, Precision: 0.8785, Recall: 0.8331, MCC: 0.7165\n",
            "Epoch 155/500\n",
            "Train - Loss: 0.3478, Acc: 0.9413, F1: 0.9413, AUC: 0.9420, Precision: 0.9677, Recall: 0.9163, MCC: 0.8840\n",
            "Val   - Loss: 0.5357, Acc: 0.8631, F1: 0.8625, AUC: 0.8632, Precision: 0.8736, Recall: 0.8517, MCC: 0.7264\n",
            "Epoch 156/500\n",
            "Train - Loss: 0.3012, Acc: 0.9782, F1: 0.9786, AUC: 0.9785, Precision: 0.9886, Recall: 0.9688, MCC: 0.9566\n",
            "Val   - Loss: 0.5551, Acc: 0.8577, F1: 0.8556, AUC: 0.8579, Precision: 0.8764, Recall: 0.8358, MCC: 0.7163\n",
            "Epoch 157/500\n",
            "Train - Loss: 0.2917, Acc: 0.9845, F1: 0.9847, AUC: 0.9848, Precision: 0.9962, Recall: 0.9735, MCC: 0.9692\n",
            "Val   - Loss: 0.6177, Acc: 0.8557, F1: 0.8564, AUC: 0.8557, Precision: 0.8598, Recall: 0.8530, MCC: 0.7114\n",
            "Epoch 158/500\n",
            "Train - Loss: 0.2909, Acc: 0.9846, F1: 0.9849, AUC: 0.9849, Precision: 0.9962, Recall: 0.9738, MCC: 0.9695\n",
            "Val   - Loss: 0.6146, Acc: 0.8564, F1: 0.8544, AUC: 0.8566, Precision: 0.8740, Recall: 0.8358, MCC: 0.7135\n",
            "Epoch 159/500\n",
            "Train - Loss: 0.2935, Acc: 0.9825, F1: 0.9828, AUC: 0.9829, Precision: 0.9948, Recall: 0.9711, MCC: 0.9654\n",
            "Val   - Loss: 0.6227, Acc: 0.8537, F1: 0.8553, AUC: 0.8537, Precision: 0.8536, Recall: 0.8570, MCC: 0.7074\n",
            "Epoch 160/500\n",
            "Train - Loss: 0.2918, Acc: 0.9840, F1: 0.9842, AUC: 0.9843, Precision: 0.9957, Recall: 0.9730, MCC: 0.9682\n",
            "Val   - Loss: 0.5656, Acc: 0.8497, F1: 0.8456, AUC: 0.8500, Precision: 0.8775, Recall: 0.8159, MCC: 0.7013\n",
            "Epoch 161/500\n",
            "Train - Loss: 0.2940, Acc: 0.9821, F1: 0.9824, AUC: 0.9825, Precision: 0.9950, Recall: 0.9701, MCC: 0.9646\n",
            "Val   - Loss: 0.6037, Acc: 0.8544, F1: 0.8556, AUC: 0.8544, Precision: 0.8556, Recall: 0.8556, MCC: 0.7087\n",
            "Epoch 162/500\n",
            "Train - Loss: 0.2909, Acc: 0.9849, F1: 0.9851, AUC: 0.9852, Precision: 0.9962, Recall: 0.9743, MCC: 0.9700\n",
            "Val   - Loss: 0.6018, Acc: 0.8537, F1: 0.8551, AUC: 0.8537, Precision: 0.8545, Recall: 0.8556, MCC: 0.7074\n",
            "Epoch 163/500\n",
            "Train - Loss: 0.2880, Acc: 0.9862, F1: 0.9864, AUC: 0.9865, Precision: 0.9967, Recall: 0.9764, MCC: 0.9726\n",
            "Val   - Loss: 0.7060, Acc: 0.8504, F1: 0.8598, AUC: 0.8498, Precision: 0.8149, Recall: 0.9099, MCC: 0.7053\n",
            "Epoch 164/500\n",
            "Train - Loss: 0.2935, Acc: 0.9825, F1: 0.9828, AUC: 0.9829, Precision: 0.9948, Recall: 0.9711, MCC: 0.9654\n",
            "Val   - Loss: 0.5324, Acc: 0.8517, F1: 0.8441, AUC: 0.8522, Precision: 0.8984, Recall: 0.7960, MCC: 0.7084\n",
            "Epoch 165/500\n",
            "Train - Loss: 0.2972, Acc: 0.9797, F1: 0.9800, AUC: 0.9800, Precision: 0.9927, Recall: 0.9676, MCC: 0.9597\n",
            "Val   - Loss: 0.6139, Acc: 0.8597, F1: 0.8642, AUC: 0.8595, Precision: 0.8445, Recall: 0.8848, MCC: 0.7201\n",
            "Epoch 166/500\n",
            "Train - Loss: 0.3010, Acc: 0.9781, F1: 0.9785, AUC: 0.9784, Precision: 0.9889, Recall: 0.9683, MCC: 0.9564\n",
            "Val   - Loss: 0.5484, Acc: 0.8637, F1: 0.8653, AUC: 0.8637, Precision: 0.8630, Recall: 0.8675, MCC: 0.7274\n",
            "Epoch 167/500\n",
            "Train - Loss: 0.2885, Acc: 0.9856, F1: 0.9859, AUC: 0.9859, Precision: 0.9963, Recall: 0.9756, MCC: 0.9715\n",
            "Val   - Loss: 0.5990, Acc: 0.8584, F1: 0.8611, AUC: 0.8583, Precision: 0.8521, Recall: 0.8702, MCC: 0.7169\n",
            "Epoch 168/500\n",
            "Train - Loss: 0.2911, Acc: 0.9846, F1: 0.9849, AUC: 0.9849, Precision: 0.9960, Recall: 0.9740, MCC: 0.9695\n",
            "Val   - Loss: 0.7287, Acc: 0.8464, F1: 0.8571, AUC: 0.8458, Precision: 0.8070, Recall: 0.9139, MCC: 0.6986\n",
            "Epoch 169/500\n",
            "Train - Loss: 0.2897, Acc: 0.9860, F1: 0.9862, AUC: 0.9862, Precision: 0.9965, Recall: 0.9761, MCC: 0.9721\n",
            "Val   - Loss: 0.5725, Acc: 0.8624, F1: 0.8650, AUC: 0.8623, Precision: 0.8560, Recall: 0.8742, MCC: 0.7249\n",
            "Epoch 170/500\n",
            "Train - Loss: 0.2885, Acc: 0.9867, F1: 0.9869, AUC: 0.9870, Precision: 0.9970, Recall: 0.9771, MCC: 0.9736\n",
            "Val   - Loss: 0.5815, Acc: 0.8557, F1: 0.8552, AUC: 0.8558, Precision: 0.8657, Recall: 0.8450, MCC: 0.7117\n",
            "Epoch 171/500\n",
            "Train - Loss: 0.2875, Acc: 0.9871, F1: 0.9874, AUC: 0.9874, Precision: 0.9975, Recall: 0.9774, MCC: 0.9745\n",
            "Val   - Loss: 0.6280, Acc: 0.8484, F1: 0.8490, AUC: 0.8484, Precision: 0.8529, Recall: 0.8450, MCC: 0.6968\n",
            "Epoch 172/500\n",
            "Train - Loss: 0.2876, Acc: 0.9868, F1: 0.9870, AUC: 0.9871, Precision: 0.9977, Recall: 0.9766, MCC: 0.9738\n",
            "Val   - Loss: 0.6259, Acc: 0.8530, F1: 0.8533, AUC: 0.8531, Precision: 0.8591, Recall: 0.8477, MCC: 0.7062\n",
            "Epoch 173/500\n",
            "Train - Loss: 0.2898, Acc: 0.9849, F1: 0.9851, AUC: 0.9852, Precision: 0.9967, Recall: 0.9738, MCC: 0.9700\n",
            "Val   - Loss: 0.7029, Acc: 0.8544, F1: 0.8586, AUC: 0.8542, Precision: 0.8412, Recall: 0.8768, MCC: 0.7093\n",
            "Epoch 174/500\n",
            "Train - Loss: 0.2924, Acc: 0.9836, F1: 0.9839, AUC: 0.9839, Precision: 0.9957, Recall: 0.9724, MCC: 0.9675\n",
            "Val   - Loss: 0.6185, Acc: 0.8651, F1: 0.8671, AUC: 0.8650, Precision: 0.8614, Recall: 0.8728, MCC: 0.7301\n",
            "Epoch 175/500\n",
            "Train - Loss: 0.2888, Acc: 0.9860, F1: 0.9863, AUC: 0.9863, Precision: 0.9970, Recall: 0.9758, MCC: 0.9723\n",
            "Val   - Loss: 0.6868, Acc: 0.8417, F1: 0.8540, AUC: 0.8410, Precision: 0.7984, Recall: 0.9179, MCC: 0.6909\n",
            "Epoch 176/500\n",
            "Train - Loss: 0.3111, Acc: 0.9701, F1: 0.9705, AUC: 0.9705, Precision: 0.9853, Recall: 0.9561, MCC: 0.9406\n",
            "Val   - Loss: 0.6460, Acc: 0.8510, F1: 0.8577, AUC: 0.8507, Precision: 0.8276, Recall: 0.8901, MCC: 0.7039\n",
            "Epoch 177/500\n",
            "Train - Loss: 0.2911, Acc: 0.9843, F1: 0.9845, AUC: 0.9846, Precision: 0.9953, Recall: 0.9740, MCC: 0.9688\n",
            "Val   - Loss: 0.5549, Acc: 0.8577, F1: 0.8546, AUC: 0.8580, Precision: 0.8817, Recall: 0.8291, MCC: 0.7169\n",
            "Epoch 178/500\n",
            "Train - Loss: 0.2877, Acc: 0.9870, F1: 0.9872, AUC: 0.9872, Precision: 0.9970, Recall: 0.9776, MCC: 0.9741\n",
            "Val   - Loss: 0.6749, Acc: 0.8570, F1: 0.8623, AUC: 0.8568, Precision: 0.8385, Recall: 0.8874, MCC: 0.7152\n",
            "Epoch 179/500\n",
            "Train - Loss: 0.2885, Acc: 0.9860, F1: 0.9863, AUC: 0.9864, Precision: 0.9975, Recall: 0.9753, MCC: 0.9724\n",
            "Val   - Loss: 0.6916, Acc: 0.8457, F1: 0.8516, AUC: 0.8454, Precision: 0.8267, Recall: 0.8781, MCC: 0.6926\n",
            "Epoch 180/500\n",
            "Train - Loss: 0.2879, Acc: 0.9866, F1: 0.9868, AUC: 0.9868, Precision: 0.9967, Recall: 0.9771, MCC: 0.9733\n",
            "Val   - Loss: 0.6192, Acc: 0.8624, F1: 0.8621, AUC: 0.8625, Precision: 0.8714, Recall: 0.8530, MCC: 0.7250\n",
            "Epoch 181/500\n",
            "Train - Loss: 0.2878, Acc: 0.9869, F1: 0.9871, AUC: 0.9872, Precision: 0.9978, Recall: 0.9766, MCC: 0.9740\n",
            "Val   - Loss: 0.7150, Acc: 0.8457, F1: 0.8568, AUC: 0.8451, Precision: 0.8054, Recall: 0.9152, MCC: 0.6976\n",
            "Epoch 182/500\n",
            "Train - Loss: 0.3020, Acc: 0.9787, F1: 0.9790, AUC: 0.9790, Precision: 0.9905, Recall: 0.9678, MCC: 0.9577\n",
            "Val   - Loss: 0.5999, Acc: 0.8517, F1: 0.8538, AUC: 0.8516, Precision: 0.8493, Recall: 0.8583, MCC: 0.7034\n",
            "Epoch 183/500\n",
            "Train - Loss: 0.2957, Acc: 0.9828, F1: 0.9831, AUC: 0.9830, Precision: 0.9924, Recall: 0.9740, MCC: 0.9658\n",
            "Val   - Loss: 0.6485, Acc: 0.8444, F1: 0.8474, AUC: 0.8442, Precision: 0.8381, Recall: 0.8570, MCC: 0.6888\n",
            "Epoch 184/500\n",
            "Train - Loss: 0.2894, Acc: 0.9857, F1: 0.9860, AUC: 0.9860, Precision: 0.9960, Recall: 0.9761, MCC: 0.9716\n",
            "Val   - Loss: 0.6266, Acc: 0.8664, F1: 0.8674, AUC: 0.8664, Precision: 0.8685, Recall: 0.8662, MCC: 0.7328\n",
            "Epoch 185/500\n",
            "Train - Loss: 0.2873, Acc: 0.9872, F1: 0.9874, AUC: 0.9875, Precision: 0.9973, Recall: 0.9777, MCC: 0.9746\n",
            "Val   - Loss: 0.6923, Acc: 0.8604, F1: 0.8633, AUC: 0.8603, Precision: 0.8527, Recall: 0.8742, MCC: 0.7209\n",
            "Epoch 186/500\n",
            "Train - Loss: 0.3188, Acc: 0.9680, F1: 0.9684, AUC: 0.9684, Precision: 0.9816, Recall: 0.9556, MCC: 0.9364\n",
            "Val   - Loss: 0.5583, Acc: 0.8637, F1: 0.8677, AUC: 0.8635, Precision: 0.8501, Recall: 0.8861, MCC: 0.7280\n",
            "Epoch 187/500\n",
            "Train - Loss: 0.2886, Acc: 0.9869, F1: 0.9871, AUC: 0.9871, Precision: 0.9968, Recall: 0.9776, MCC: 0.9740\n",
            "Val   - Loss: 0.5665, Acc: 0.8550, F1: 0.8517, AUC: 0.8553, Precision: 0.8799, Recall: 0.8252, MCC: 0.7116\n",
            "Epoch 188/500\n",
            "Train - Loss: 0.2885, Acc: 0.9866, F1: 0.9868, AUC: 0.9868, Precision: 0.9970, Recall: 0.9767, MCC: 0.9733\n",
            "Val   - Loss: 0.5855, Acc: 0.8557, F1: 0.8564, AUC: 0.8557, Precision: 0.8598, Recall: 0.8530, MCC: 0.7114\n",
            "Epoch 189/500\n",
            "Train - Loss: 0.2887, Acc: 0.9858, F1: 0.9860, AUC: 0.9861, Precision: 0.9968, Recall: 0.9754, MCC: 0.9718\n",
            "Val   - Loss: 0.5738, Acc: 0.8550, F1: 0.8525, AUC: 0.8553, Precision: 0.8757, Recall: 0.8305, MCC: 0.7112\n",
            "Epoch 190/500\n",
            "Train - Loss: 0.2864, Acc: 0.9876, F1: 0.9878, AUC: 0.9878, Precision: 0.9987, Recall: 0.9771, MCC: 0.9753\n",
            "Val   - Loss: 0.6724, Acc: 0.8510, F1: 0.8555, AUC: 0.8508, Precision: 0.8376, Recall: 0.8742, MCC: 0.7026\n",
            "Epoch 191/500\n",
            "Train - Loss: 0.2881, Acc: 0.9865, F1: 0.9867, AUC: 0.9868, Precision: 0.9972, Recall: 0.9764, MCC: 0.9732\n",
            "Val   - Loss: 0.6843, Acc: 0.8544, F1: 0.8584, AUC: 0.8542, Precision: 0.8420, Recall: 0.8755, MCC: 0.7092\n",
            "Epoch 192/500\n",
            "Train - Loss: 0.2883, Acc: 0.9850, F1: 0.9853, AUC: 0.9854, Precision: 0.9965, Recall: 0.9743, MCC: 0.9703\n",
            "Val   - Loss: 0.5803, Acc: 0.8403, F1: 0.8306, AUC: 0.8409, Precision: 0.8933, Recall: 0.7762, MCC: 0.6871\n",
            "Epoch 193/500\n",
            "Train - Loss: 0.2888, Acc: 0.9855, F1: 0.9858, AUC: 0.9859, Precision: 0.9972, Recall: 0.9746, MCC: 0.9714\n",
            "Val   - Loss: 0.6426, Acc: 0.8557, F1: 0.8581, AUC: 0.8556, Precision: 0.8514, Recall: 0.8649, MCC: 0.7115\n",
            "Epoch 194/500\n",
            "Train - Loss: 0.2931, Acc: 0.9833, F1: 0.9835, AUC: 0.9836, Precision: 0.9953, Recall: 0.9720, MCC: 0.9669\n",
            "Val   - Loss: 0.7228, Acc: 0.8330, F1: 0.8447, AUC: 0.8324, Precision: 0.7953, Recall: 0.9007, MCC: 0.6716\n",
            "Epoch 195/500\n",
            "Train - Loss: 0.2893, Acc: 0.9864, F1: 0.9866, AUC: 0.9866, Precision: 0.9957, Recall: 0.9777, MCC: 0.9729\n",
            "Val   - Loss: 0.7703, Acc: 0.8403, F1: 0.8511, AUC: 0.8398, Precision: 0.8035, Recall: 0.9046, MCC: 0.6859\n",
            "Epoch 196/500\n",
            "Train - Loss: 0.3098, Acc: 0.9730, F1: 0.9734, AUC: 0.9733, Precision: 0.9855, Recall: 0.9616, MCC: 0.9463\n",
            "Val   - Loss: 0.6461, Acc: 0.8424, F1: 0.8503, AUC: 0.8420, Precision: 0.8161, Recall: 0.8874, MCC: 0.6871\n",
            "Epoch 197/500\n",
            "Train - Loss: 0.3006, Acc: 0.9789, F1: 0.9793, AUC: 0.9792, Precision: 0.9894, Recall: 0.9694, MCC: 0.9581\n",
            "Val   - Loss: 0.5420, Acc: 0.8617, F1: 0.8595, AUC: 0.8619, Precision: 0.8816, Recall: 0.8384, MCC: 0.7244\n",
            "Epoch 198/500\n",
            "Train - Loss: 0.2874, Acc: 0.9869, F1: 0.9871, AUC: 0.9872, Precision: 0.9975, Recall: 0.9769, MCC: 0.9740\n",
            "Val   - Loss: 0.6121, Acc: 0.8550, F1: 0.8562, AUC: 0.8550, Precision: 0.8568, Recall: 0.8556, MCC: 0.7101\n",
            "Epoch 199/500\n",
            "Train - Loss: 0.2851, Acc: 0.9886, F1: 0.9888, AUC: 0.9888, Precision: 0.9982, Recall: 0.9795, MCC: 0.9773\n",
            "Val   - Loss: 0.5908, Acc: 0.8597, F1: 0.8592, AUC: 0.8598, Precision: 0.8697, Recall: 0.8490, MCC: 0.7197\n",
            "Epoch 200/500\n",
            "Train - Loss: 0.2851, Acc: 0.9881, F1: 0.9883, AUC: 0.9883, Precision: 0.9972, Recall: 0.9795, MCC: 0.9763\n",
            "Val   - Loss: 0.6748, Acc: 0.8584, F1: 0.8607, AUC: 0.8583, Precision: 0.8540, Recall: 0.8675, MCC: 0.7168\n",
            "Epoch 201/500\n",
            "Train - Loss: 0.2849, Acc: 0.9884, F1: 0.9886, AUC: 0.9886, Precision: 0.9978, Recall: 0.9795, MCC: 0.9769\n",
            "Val   - Loss: 0.6300, Acc: 0.8624, F1: 0.8595, AUC: 0.8626, Precision: 0.8861, Recall: 0.8344, MCC: 0.7262\n",
            "Epoch 202/500\n",
            "Train - Loss: 0.2901, Acc: 0.9853, F1: 0.9856, AUC: 0.9856, Precision: 0.9952, Recall: 0.9761, MCC: 0.9708\n",
            "Val   - Loss: 0.5967, Acc: 0.8624, F1: 0.8612, AUC: 0.8625, Precision: 0.8765, Recall: 0.8464, MCC: 0.7253\n",
            "Epoch 203/500\n",
            "Train - Loss: 0.2871, Acc: 0.9868, F1: 0.9870, AUC: 0.9871, Precision: 0.9967, Recall: 0.9776, MCC: 0.9738\n",
            "Val   - Loss: 0.7705, Acc: 0.8403, F1: 0.8471, AUC: 0.8400, Precision: 0.8193, Recall: 0.8768, MCC: 0.6822\n",
            "Epoch 204/500\n",
            "Train - Loss: 0.2887, Acc: 0.9862, F1: 0.9864, AUC: 0.9865, Precision: 0.9965, Recall: 0.9766, MCC: 0.9726\n",
            "Val   - Loss: 0.5149, Acc: 0.8637, F1: 0.8593, AUC: 0.8641, Precision: 0.8964, Recall: 0.8252, MCC: 0.7300\n",
            "Epoch 205/500\n",
            "Train - Loss: 0.2887, Acc: 0.9857, F1: 0.9860, AUC: 0.9860, Precision: 0.9952, Recall: 0.9769, MCC: 0.9716\n",
            "Val   - Loss: 0.6231, Acc: 0.8564, F1: 0.8612, AUC: 0.8561, Precision: 0.8401, Recall: 0.8834, MCC: 0.7136\n",
            "Epoch 206/500\n",
            "Train - Loss: 0.2847, Acc: 0.9885, F1: 0.9887, AUC: 0.9887, Precision: 0.9977, Recall: 0.9798, MCC: 0.9771\n",
            "Val   - Loss: 0.6447, Acc: 0.8323, F1: 0.8323, AUC: 0.8324, Precision: 0.8396, Recall: 0.8252, MCC: 0.6648\n",
            "Epoch 207/500\n",
            "Train - Loss: 0.2902, Acc: 0.9842, F1: 0.9845, AUC: 0.9845, Precision: 0.9953, Recall: 0.9738, MCC: 0.9687\n",
            "Val   - Loss: 0.6065, Acc: 0.8484, F1: 0.8436, AUC: 0.8487, Precision: 0.8793, Recall: 0.8106, MCC: 0.6991\n",
            "Epoch 208/500\n",
            "Train - Loss: 0.2881, Acc: 0.9865, F1: 0.9867, AUC: 0.9867, Precision: 0.9964, Recall: 0.9772, MCC: 0.9731\n",
            "Val   - Loss: 0.6939, Acc: 0.8530, F1: 0.8625, AUC: 0.8525, Precision: 0.8166, Recall: 0.9139, MCC: 0.7109\n",
            "Epoch 209/500\n",
            "Train - Loss: 0.2859, Acc: 0.9876, F1: 0.9878, AUC: 0.9878, Precision: 0.9969, Recall: 0.9789, MCC: 0.9753\n",
            "Val   - Loss: 0.6913, Acc: 0.8617, F1: 0.8648, AUC: 0.8616, Precision: 0.8531, Recall: 0.8768, MCC: 0.7236\n",
            "Epoch 210/500\n",
            "Train - Loss: 0.2888, Acc: 0.9853, F1: 0.9855, AUC: 0.9856, Precision: 0.9960, Recall: 0.9753, MCC: 0.9708\n",
            "Val   - Loss: 0.5898, Acc: 0.8524, F1: 0.8458, AUC: 0.8528, Precision: 0.8938, Recall: 0.8026, MCC: 0.7087\n",
            "Epoch 211/500\n",
            "Train - Loss: 0.2877, Acc: 0.9859, F1: 0.9861, AUC: 0.9862, Precision: 0.9963, Recall: 0.9761, MCC: 0.9720\n",
            "Val   - Loss: 0.5539, Acc: 0.8564, F1: 0.8485, AUC: 0.8569, Precision: 0.9066, Recall: 0.7974, MCC: 0.7184\n",
            "Epoch 212/500\n",
            "Train - Loss: 0.2879, Acc: 0.9855, F1: 0.9857, AUC: 0.9857, Precision: 0.9957, Recall: 0.9759, MCC: 0.9711\n",
            "Val   - Loss: 0.7152, Acc: 0.8557, F1: 0.8543, AUC: 0.8559, Precision: 0.8707, Recall: 0.8384, MCC: 0.7120\n",
            "Epoch 213/500\n",
            "Train - Loss: 0.2872, Acc: 0.9870, F1: 0.9872, AUC: 0.9872, Precision: 0.9960, Recall: 0.9785, MCC: 0.9741\n",
            "Val   - Loss: 0.7030, Acc: 0.8557, F1: 0.8608, AUC: 0.8555, Precision: 0.8381, Recall: 0.8848, MCC: 0.7124\n",
            "Epoch 214/500\n",
            "Train - Loss: 0.2867, Acc: 0.9874, F1: 0.9876, AUC: 0.9876, Precision: 0.9967, Recall: 0.9787, MCC: 0.9749\n",
            "Val   - Loss: 0.6840, Acc: 0.8544, F1: 0.8601, AUC: 0.8541, Precision: 0.8344, Recall: 0.8874, MCC: 0.7100\n",
            "Epoch 215/500\n",
            "Train - Loss: 0.2843, Acc: 0.9889, F1: 0.9891, AUC: 0.9891, Precision: 0.9983, Recall: 0.9800, MCC: 0.9779\n",
            "Val   - Loss: 0.8047, Acc: 0.8383, F1: 0.8468, AUC: 0.8379, Precision: 0.8109, Recall: 0.8861, MCC: 0.6794\n",
            "Epoch 216/500\n",
            "Train - Loss: 0.2940, Acc: 0.9818, F1: 0.9821, AUC: 0.9821, Precision: 0.9930, Recall: 0.9714, MCC: 0.9638\n",
            "Val   - Loss: 0.6396, Acc: 0.8537, F1: 0.8537, AUC: 0.8538, Precision: 0.8612, Recall: 0.8464, MCC: 0.7075\n",
            "Epoch 217/500\n",
            "Train - Loss: 0.2866, Acc: 0.9871, F1: 0.9874, AUC: 0.9874, Precision: 0.9969, Recall: 0.9780, MCC: 0.9744\n",
            "Val   - Loss: 0.6368, Acc: 0.8657, F1: 0.8682, AUC: 0.8656, Precision: 0.8597, Recall: 0.8768, MCC: 0.7315\n",
            "Epoch 218/500\n",
            "Train - Loss: 0.2888, Acc: 0.9861, F1: 0.9864, AUC: 0.9864, Precision: 0.9960, Recall: 0.9769, MCC: 0.9724\n",
            "Val   - Loss: 0.6476, Acc: 0.8577, F1: 0.8570, AUC: 0.8578, Precision: 0.8692, Recall: 0.8450, MCC: 0.7158\n",
            "Epoch 219/500\n",
            "Train - Loss: 0.2864, Acc: 0.9876, F1: 0.9879, AUC: 0.9879, Precision: 0.9975, Recall: 0.9784, MCC: 0.9755\n",
            "Val   - Loss: 0.6465, Acc: 0.8597, F1: 0.8645, AUC: 0.8595, Precision: 0.8428, Recall: 0.8874, MCC: 0.7203\n",
            "Epoch 220/500\n",
            "Train - Loss: 0.2853, Acc: 0.9878, F1: 0.9880, AUC: 0.9881, Precision: 0.9972, Recall: 0.9790, MCC: 0.9758\n",
            "Val   - Loss: 0.6491, Acc: 0.8557, F1: 0.8583, AUC: 0.8556, Precision: 0.8505, Recall: 0.8662, MCC: 0.7115\n",
            "Epoch 221/500\n",
            "Train - Loss: 0.2855, Acc: 0.9876, F1: 0.9878, AUC: 0.9878, Precision: 0.9978, Recall: 0.9779, MCC: 0.9753\n",
            "Val   - Loss: 0.7362, Acc: 0.8570, F1: 0.8588, AUC: 0.8570, Precision: 0.8555, Recall: 0.8623, MCC: 0.7141\n",
            "Epoch 222/500\n",
            "Train - Loss: 0.2915, Acc: 0.9845, F1: 0.9847, AUC: 0.9847, Precision: 0.9945, Recall: 0.9751, MCC: 0.9691\n",
            "Val   - Loss: 0.7893, Acc: 0.8323, F1: 0.8474, AUC: 0.8315, Precision: 0.7831, Recall: 0.9232, MCC: 0.6752\n",
            "Epoch 223/500\n",
            "Train - Loss: 0.2921, Acc: 0.9846, F1: 0.9849, AUC: 0.9849, Precision: 0.9945, Recall: 0.9754, MCC: 0.9694\n",
            "Val   - Loss: 0.6381, Acc: 0.8684, F1: 0.8722, AUC: 0.8682, Precision: 0.8550, Recall: 0.8901, MCC: 0.7373\n",
            "Epoch 224/500\n",
            "Train - Loss: 0.2912, Acc: 0.9855, F1: 0.9857, AUC: 0.9857, Precision: 0.9944, Recall: 0.9772, MCC: 0.9711\n",
            "Val   - Loss: 0.5395, Acc: 0.8637, F1: 0.8605, AUC: 0.8640, Precision: 0.8897, Recall: 0.8331, MCC: 0.7291\n",
            "Epoch 225/500\n",
            "Train - Loss: 0.2863, Acc: 0.9881, F1: 0.9883, AUC: 0.9883, Precision: 0.9970, Recall: 0.9797, MCC: 0.9763\n",
            "Val   - Loss: 0.6410, Acc: 0.8671, F1: 0.8737, AUC: 0.8667, Precision: 0.8390, Recall: 0.9113, MCC: 0.7367\n",
            "Epoch 226/500\n",
            "Train - Loss: 0.2852, Acc: 0.9887, F1: 0.9889, AUC: 0.9889, Precision: 0.9972, Recall: 0.9808, MCC: 0.9776\n",
            "Val   - Loss: 0.6430, Acc: 0.8637, F1: 0.8689, AUC: 0.8635, Precision: 0.8439, Recall: 0.8954, MCC: 0.7287\n",
            "Epoch 227/500\n",
            "Train - Loss: 0.2862, Acc: 0.9880, F1: 0.9882, AUC: 0.9882, Precision: 0.9965, Recall: 0.9800, MCC: 0.9761\n",
            "Val   - Loss: 0.6880, Acc: 0.8651, F1: 0.8703, AUC: 0.8648, Precision: 0.8443, Recall: 0.8980, MCC: 0.7315\n",
            "Epoch 228/500\n",
            "Train - Loss: 0.2847, Acc: 0.9891, F1: 0.9893, AUC: 0.9893, Precision: 0.9982, Recall: 0.9805, MCC: 0.9783\n",
            "Val   - Loss: 0.8654, Acc: 0.8390, F1: 0.8544, AUC: 0.8382, Precision: 0.7856, Recall: 0.9364, MCC: 0.6906\n",
            "Epoch 229/500\n",
            "Train - Loss: 0.3255, Acc: 0.9581, F1: 0.9583, AUC: 0.9586, Precision: 0.9796, Recall: 0.9379, MCC: 0.9170\n",
            "Val   - Loss: 0.5666, Acc: 0.8637, F1: 0.8668, AUC: 0.8636, Precision: 0.8546, Recall: 0.8795, MCC: 0.7277\n",
            "Epoch 230/500\n",
            "Train - Loss: 0.2875, Acc: 0.9870, F1: 0.9872, AUC: 0.9872, Precision: 0.9952, Recall: 0.9793, MCC: 0.9741\n",
            "Val   - Loss: 0.5896, Acc: 0.8671, F1: 0.8695, AUC: 0.8670, Precision: 0.8610, Recall: 0.8781, MCC: 0.7342\n",
            "Epoch 231/500\n",
            "Train - Loss: 0.2880, Acc: 0.9868, F1: 0.9870, AUC: 0.9870, Precision: 0.9954, Recall: 0.9789, MCC: 0.9737\n",
            "Val   - Loss: 0.6226, Acc: 0.8697, F1: 0.8715, AUC: 0.8697, Precision: 0.8675, Recall: 0.8755, MCC: 0.7395\n",
            "Epoch 232/500\n",
            "Train - Loss: 0.2853, Acc: 0.9884, F1: 0.9886, AUC: 0.9886, Precision: 0.9975, Recall: 0.9798, MCC: 0.9769\n",
            "Val   - Loss: 0.6466, Acc: 0.8664, F1: 0.8711, AUC: 0.8661, Precision: 0.8482, Recall: 0.8954, MCC: 0.7338\n",
            "Epoch 233/500\n",
            "Train - Loss: 0.2837, Acc: 0.9891, F1: 0.9893, AUC: 0.9894, Precision: 0.9978, Recall: 0.9810, MCC: 0.9784\n",
            "Val   - Loss: 0.6113, Acc: 0.8758, F1: 0.8765, AUC: 0.8758, Precision: 0.8788, Recall: 0.8742, MCC: 0.7515\n",
            "Epoch 234/500\n",
            "Train - Loss: 0.2846, Acc: 0.9890, F1: 0.9892, AUC: 0.9892, Precision: 0.9978, Recall: 0.9807, MCC: 0.9781\n",
            "Val   - Loss: 0.6450, Acc: 0.8691, F1: 0.8709, AUC: 0.8690, Precision: 0.8663, Recall: 0.8755, MCC: 0.7381\n",
            "Epoch 235/500\n",
            "Train - Loss: 0.2849, Acc: 0.9883, F1: 0.9885, AUC: 0.9885, Precision: 0.9975, Recall: 0.9797, MCC: 0.9768\n",
            "Val   - Loss: 0.6969, Acc: 0.8671, F1: 0.8686, AUC: 0.8670, Precision: 0.8658, Recall: 0.8715, MCC: 0.7341\n",
            "Epoch 236/500\n",
            "Train - Loss: 0.2873, Acc: 0.9869, F1: 0.9871, AUC: 0.9871, Precision: 0.9965, Recall: 0.9779, MCC: 0.9739\n",
            "Val   - Loss: 0.6043, Acc: 0.8584, F1: 0.8571, AUC: 0.8585, Precision: 0.8724, Recall: 0.8424, MCC: 0.7173\n",
            "Epoch 237/500\n",
            "Train - Loss: 0.2851, Acc: 0.9882, F1: 0.9884, AUC: 0.9885, Precision: 0.9975, Recall: 0.9795, MCC: 0.9766\n",
            "Val   - Loss: 0.6757, Acc: 0.8657, F1: 0.8672, AUC: 0.8657, Precision: 0.8654, Recall: 0.8689, MCC: 0.7314\n",
            "Epoch 238/500\n",
            "Train - Loss: 0.2845, Acc: 0.9891, F1: 0.9893, AUC: 0.9893, Precision: 0.9980, Recall: 0.9807, MCC: 0.9783\n",
            "Val   - Loss: 0.7171, Acc: 0.8637, F1: 0.8687, AUC: 0.8635, Precision: 0.8448, Recall: 0.8940, MCC: 0.7286\n",
            "Epoch 239/500\n",
            "Train - Loss: 0.2834, Acc: 0.9898, F1: 0.9900, AUC: 0.9900, Precision: 0.9985, Recall: 0.9816, MCC: 0.9798\n",
            "Val   - Loss: 0.7542, Acc: 0.8457, F1: 0.8543, AUC: 0.8452, Precision: 0.8157, Recall: 0.8967, MCC: 0.6946\n",
            "Epoch 240/500\n",
            "Train - Loss: 0.2876, Acc: 0.9866, F1: 0.9868, AUC: 0.9868, Precision: 0.9960, Recall: 0.9777, MCC: 0.9733\n",
            "Val   - Loss: 0.6015, Acc: 0.8524, F1: 0.8496, AUC: 0.8526, Precision: 0.8739, Recall: 0.8265, MCC: 0.7059\n"
          ]
        }
      ]
    }
  ]
}