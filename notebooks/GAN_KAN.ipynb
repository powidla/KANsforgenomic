{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLMUy-VNTdeb"
      },
      "outputs": [],
      "source": [
        "!pip install pybedtools\n",
        "!pip install Bio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVIHkIBkXP1D"
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pybedtools\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.parallel\n",
        "import torch.utils.data\n",
        "from torchsummary import summary\n",
        "import logging\n",
        "from torch import autograd\n",
        "from torch import optim\n",
        "import pprint\n",
        "from sklearn.neighbors import KDTree\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import editdistance\n",
        "import argparse\n",
        "import json\n",
        "import datetime\n",
        "import pickle as pk\n",
        "from sklearn import metrics\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H7r17-gnVJZ"
      },
      "outputs": [],
      "source": [
        "codes = {\n",
        " 'A': [1., 0., 0., 0., 0.],\n",
        " 'T': [0., 1., 0., 0., 0.],\n",
        " 'G': [0., 0., 1., 0., 0.],\n",
        " 'C': [0., 0., 0., 1., 0.],\n",
        " 'N': [0., 0., 0., 0., 1.],\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr8ps8sZ2fCn"
      },
      "outputs": [],
      "source": [
        "def KL_divergence(real: pd.Series, generated: pd.Series) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    This function encapsulates the logic of evaluating the KL divergence metric\n",
        "    between two sequences.\n",
        "    Returns\n",
        "    -------\n",
        "    kl_divergence: Float\n",
        "      The KL divergence between the input and output (generated)\n",
        "      sequences' distribution\n",
        "    \"\"\"\n",
        "\n",
        "    kl_pq = rel_entr(real, generated)\n",
        "    return np.sum(kl_pq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIbPcVf4i14D"
      },
      "outputs": [],
      "source": [
        "def diversity(\n",
        "    generated, real, scoring_metric=KL_divergence, plot_motif_probs=False\n",
        "):\n",
        "    \"\"\"\n",
        "    This function encapsulates the logic of evaluating the difference between the distribution\n",
        "    of frequencies between generated (diffusion/df_motifs_a) and the input (training/df_motifs_b) for an arbitrary metric (\"motif_scoring_metric\")\n",
        "\n",
        "    Please note that some metrics, like KL_divergence, are not metrics in official sense. Reason\n",
        "    for that is that they dont satisfy certain properties, such as in KL case, the simmetry property.\n",
        "    Hence it makes a big difference what are the positions of input.\n",
        "    \"\"\"\n",
        "    set_all_data = set(generated.index.values.tolist() + real.index.values.tolist())\n",
        "    create_new_matrix = []\n",
        "    for x in set_all_data:\n",
        "        list_in = []\n",
        "        list_in.append(x)  # adding the name\n",
        "        if x in generated.index:\n",
        "            list_in.append(generated.loc[x][0])\n",
        "        else:\n",
        "            list_in.append(1)\n",
        "\n",
        "        if x in real.index:\n",
        "            list_in.append(real.loc[x][0])\n",
        "        else:\n",
        "            list_in.append(1)\n",
        "\n",
        "        create_new_matrix.append(list_in)\n",
        "\n",
        "    df_kl = pd.DataFrame(create_new_matrix, columns=['Flipon', 'generated', 'real'])\n",
        "\n",
        "    df_kl['Generated_seqs'] = df_kl['generated'] / df_kl['generated'].sum()\n",
        "    df_kl['Training_seqs'] = df_kl['real'] / df_kl['real'].sum()\n",
        "    plt.rcParams[\"figure.figsize\"] = (3, 3)\n",
        "    sns.regplot(x='Generated_seqs', y='Training_seqs', data=df_kl)\n",
        "    plt.xlabel('Generated_seqs')\n",
        "    plt.ylabel('Training Seqs')\n",
        "    plt.title('Motifs Probs')\n",
        "    plt.show()\n",
        "\n",
        "    return scoring_metric(df_kl['Genereated_seqs'].values, df_kl['Training_seqs'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sbxpvP2i373"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoding(sequence, target_length):\n",
        "    \"\"\"Convert DNA sequence to one-hot encoding.\"\"\"\n",
        "    nucleotides = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    one_hot_seq = np.zeros((target_length, len(nucleotides)))\n",
        "\n",
        "    for i, nucleotide in enumerate(sequence[:target_length]):\n",
        "        if nucleotide in nucleotides:\n",
        "            one_hot_seq[i, nucleotides[nucleotide]] = 1\n",
        "\n",
        "    # Flatten the one-hot encoding to a 1D vector\n",
        "    one_hot_flat = one_hot_seq.flatten()\n",
        "\n",
        "    return one_hot_flat\n",
        "\n",
        "def preprocess_sequences(sequences, target_length):\n",
        "    \"\"\"Pad or truncate sequences to the target length.\"\"\"\n",
        "    return [seq.ljust(target_length, 'N')[:target_length] for seq in sequences]\n",
        "\n",
        "def calculate_diversity_optimized_one_hot(dataset, target_length):\n",
        "    \"\"\"Calculate diversity within a single dataset using KDTree and one-hot encoding.\"\"\"\n",
        "    diversity = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    sequences = preprocess_sequences(dataset, target_length)\n",
        "\n",
        "    sequences_one_hot = [one_hot_encoding(seq, target_length) for seq in sequences]\n",
        "\n",
        "    kdtree = KDTree(sequences_one_hot)\n",
        "\n",
        "    for i, seq_i in enumerate(sequences_one_hot):\n",
        "        for j, seq_j in enumerate(sequences_one_hot):\n",
        "            if i != j:\n",
        "\n",
        "                edit_dist_ij = editdistance.eval(seq_i, seq_j)\n",
        "                diversity += edit_dist_ij\n",
        "                total_pairs += 1\n",
        "\n",
        "    if total_pairs > 0:\n",
        "        diversity /= total_pairs\n",
        "\n",
        "    return diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3y5a3YTgi7Ay"
      },
      "outputs": [],
      "source": [
        "def one_hot_encoding(sequence, target_length):\n",
        "    \"\"\"Convert DNA sequence to one-hot encoding.\"\"\"\n",
        "    nucleotides = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    one_hot_seq = np.zeros((target_length, len(nucleotides)))\n",
        "\n",
        "    for i, nucleotide in enumerate(sequence[:target_length]):\n",
        "        if nucleotide in nucleotides:\n",
        "            one_hot_seq[i, nucleotides[nucleotide]] = 1\n",
        "\n",
        "    # Flatten the one-hot encoding to a 1D vector\n",
        "    one_hot_flat = one_hot_seq.flatten()\n",
        "\n",
        "    return one_hot_flat\n",
        "\n",
        "def preprocess_sequences(sequences, target_length):\n",
        "    \"\"\"Pad or truncate sequences to the target length.\"\"\"\n",
        "    return [seq.ljust(target_length, 'N')[:target_length] for seq in sequences]\n",
        "\n",
        "def calculate_novelty_optimized_one_hot(generated_sequences, initial_sequences, target_length):\n",
        "    \"\"\"Calculate novelty of the generated sequences using KDTree and one-hot encoding.\"\"\"\n",
        "    novelty = 0.0\n",
        "    total_pairs = 0\n",
        "\n",
        "    initial_sequences = preprocess_sequences(initial_sequences, target_length)\n",
        "    generated_sequences = preprocess_sequences(generated_sequences, target_length)\n",
        "\n",
        "    initial_sequences_one_hot = [one_hot_encoding(seq, target_length) for seq in initial_sequences]\n",
        "    generated_sequences_one_hot = [one_hot_encoding(seq, target_length) for seq in generated_sequences]\n",
        "\n",
        "    kdtree = KDTree(initial_sequences_one_hot)\n",
        "\n",
        "    for gen_seq_one_hot in generated_sequences_one_hot:\n",
        "\n",
        "        distance, _ = kdtree.query(gen_seq_one_hot)\n",
        "        novelty += distance\n",
        "        total_pairs += 1\n",
        "\n",
        "    if total_pairs > 0:\n",
        "        novelty /= total_pairs\n",
        "\n",
        "    return novelty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsUL0By29rm7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrDHln359sM4"
      },
      "source": [
        "#KAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqJhhvu79pRT"
      },
      "source": [
        "Linear KAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPaiuDQH9pYi"
      },
      "outputs": [],
      "source": [
        "class KANLinear(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = torch.nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = torch.nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)\n",
        "                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the B-spline bases for the given input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: B-spline bases tensor of shape (batch_size, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid: torch.Tensor = (\n",
        "            self.grid\n",
        "        )  # (in_features, grid_size + 2 * spline_order + 1)\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the coefficients of the curve that interpolates the given points.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, in_features).\n",
        "            y (torch.Tensor): Output tensor of shape (batch_size, in_features, out_features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Coefficients tensor of shape (out_features, in_features, grid_size + spline_order).\n",
        "        \"\"\"\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(\n",
        "            0, 1\n",
        "        )  # (in_features, batch_size, grid_size + spline_order)\n",
        "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
        "        solution = torch.linalg.lstsq(\n",
        "            A, B\n",
        "        ).solution  # (in_features, grid_size + spline_order, out_features)\n",
        "        result = solution.permute(\n",
        "            2, 0, 1\n",
        "        )  # (out_features, in_features, grid_size + spline_order)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        assert x.size(-1) == self.in_features\n",
        "        original_shape = x.shape\n",
        "        x = x.reshape(-1, self.in_features)\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        output = base_output + spline_output\n",
        "\n",
        "        output = output.reshape(*original_shape[:-1], self.out_features)\n",
        "        return output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
        "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
        "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(\n",
        "            1, 0, 2\n",
        "        )  # (batch, in, out)\n",
        "\n",
        "        # sort each channel individually to collect data distribution\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.concatenate(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        \"\"\"\n",
        "        Compute the regularization loss.\n",
        "\n",
        "        The L1 regularization is now computed as mean absolute value of the spline\n",
        "        weights. The authors implementation also includes this term in addition to the\n",
        "        sample-based regularization.\n",
        "        \"\"\"\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "\n",
        "class KAN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                KANLinear(\n",
        "                    in_features,\n",
        "                    out_features,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=True):\n",
        "        for layer in self.layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        return sum(\n",
        "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
        "            for layer in self.layers\n",
        "        )\n",
        "\n",
        "class KAN(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        layers_hidden,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        base_activation=torch.nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KAN, self).__init__()\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        self.layers = torch.nn.ModuleList()\n",
        "        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n",
        "            self.layers.append(\n",
        "                KANLinear(\n",
        "                    in_features,\n",
        "                    out_features,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, update_grid=False):\n",
        "        for layer in self.layers:\n",
        "            if update_grid:\n",
        "                layer.update_grid(x)\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        return sum(\n",
        "            layer.regularization_loss(regularize_activation, regularize_entropy)\n",
        "            for layer in self.layers\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBrURPDx-FgE"
      },
      "source": [
        "kan conv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtZVb2EI-Hls"
      },
      "outputs": [],
      "source": [
        "#Util\n",
        "def add_padding_1d(array: np.ndarray, padding: int) -> np.ndarray:\n",
        "    \"\"\"Adds padding to a 1D array.\"\"\"\n",
        "    n = array.shape[0]\n",
        "    padded_array = np.zeros(n + 2 * padding)\n",
        "    padded_array[padding: n + padding] = array\n",
        "    return padded_array\n",
        "\n",
        "\n",
        "def calc_out_dims_1d(array, kernel_size, stride, dilation, padding):\n",
        "    \"\"\"Calculate output dimensions for 1D convolution.\"\"\"\n",
        "    batch_size, n_channels, n = matrix.shape\n",
        "    out_size = np.floor((n + 2 * padding - kernel_size - (kernel_size - 1) * (dilation - 1)) / stride).astype(int) + 1\n",
        "    return out_size, batch_size, n_channels\n",
        "\n",
        "\n",
        "def multiple_convs_kan_conv1d(array,\n",
        "                               kernels,\n",
        "                               kernel_size,\n",
        "                               out_channels,\n",
        "                               stride=1,\n",
        "                               dilation=1,\n",
        "                               padding=0,\n",
        "                               device=\"cuda\") -> torch.Tensor:\n",
        "    \"\"\"Performs a 1D convolution with multiple kernels on the input array using specified stride, dilation, and padding.\n",
        "\n",
        "    Args:\n",
        "        array (torch.Tensor): 1D tensor of shape (batch_size, channels, length).\n",
        "        kernels (list): List of kernel functions to be applied.\n",
        "        kernel_size (int): Size of the 1D kernel.\n",
        "        out_channels (int): Number of output channels.\n",
        "        stride (int): Stride along the length of the array. Default is 1.\n",
        "        dilation (int): Dilation rate along the length of the array. Default is 1.\n",
        "        padding (int): Number of elements to pad on each side. Default is 0.\n",
        "        device (str): Device to perform calculations on. Default is \"cuda\".\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Feature map after convolution with shape (batch_size, out_channels, length_out).\n",
        "    \"\"\"\n",
        "    length_out, batch_size = calc_out_dims_1d(array, kernel_size, stride, dilation, padding)\n",
        "    n_convs = len(kernels)\n",
        "\n",
        "    array_out = torch.zeros((batch_size, out_channels, length_out)).to(device)\n",
        "\n",
        "    array = F.pad(array, (padding, padding), mode='constant', value=0)\n",
        "    conv_groups = array.unfold(2, kernel_size, stride)\n",
        "    conv_groups = conv_groups.contiguous()\n",
        "\n",
        "    kern_per_out = len(kernels) // out_channels\n",
        "\n",
        "    for c_out in range(out_channels):\n",
        "        out_channel_accum = torch.zeros((batch_size, length_out), device=device)\n",
        "\n",
        "        for k_idx in range(kern_per_out):\n",
        "            kernel = kernels[c_out * kern_per_out + k_idx]\n",
        "            conv_result = kernel(conv_groups.view(-1, 1, kernel_size))\n",
        "            out_channel_accum += conv_result.view(batch_size, length_out)\n",
        "\n",
        "        array_out[:, c_out, :] = out_channel_accum\n",
        "\n",
        "    return array_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGf1kJxM-HoG"
      },
      "outputs": [],
      "source": [
        "def kan_conv1d(matrix: torch.Tensor,\n",
        "               kernel,\n",
        "               kernel_size: int,\n",
        "               stride: int = 1,\n",
        "               dilation: int = 1,\n",
        "               padding: int = 0,\n",
        "               device: str = \"cpu\") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Performs a 1D convolution with the given kernel over a 1D matrix using the defined stride, dilation, and padding.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): 3D tensor (batch_size, channels, width) to be convolved.\n",
        "        kernel (function): Kernel function to apply on the 1D patches of the matrix.\n",
        "        kernel_size (int): Size of the kernel (assumed to be square).\n",
        "        stride (int, optional): Stride along the width axis. Defaults to 1.\n",
        "        dilation (int, optional): Dilation along the width axis. Defaults to 1.\n",
        "        padding (int, optional): Padding along the width axis. Defaults to 0.\n",
        "        device (str): Device to perform the operation on (e.g., \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: 1D Feature map after convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, n_channels, width_in = matrix.shape\n",
        "    width_out = ((width_in + 2 * padding - dilation * (kernel_size - 1) - 1) // stride) + 1\n",
        "    matrix_out = torch.zeros((batch_size, n_channels, width_out), device=device)\n",
        "\n",
        "    matrix_padded = torch.nn.functional.pad(matrix, (padding, padding))\n",
        "\n",
        "    for i in range(width_out):\n",
        "\n",
        "        start = i * stride\n",
        "        end = start + kernel_size * dilation\n",
        "        patch = matrix_padded[:, :, start:end:dilation]\n",
        "\n",
        "        matrix_out[:, :, i] = kernel.forward(patch).squeeze(-1)\n",
        "\n",
        "    return matrix_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1Lcm0y2-TId"
      },
      "outputs": [],
      "source": [
        "class KAN_Convolutional_Layer_1D(torch.nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1, kernel_size=5, stride=1, padding=0, dilation=1, device=\"cuda\"):\n",
        "        super(KAN_Convolutional_Layer_1D, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.device = device\n",
        "        self.convs = torch.nn.ModuleList([KAN_Convolution_1D(kernel_size, stride, padding, dilation, device) for _ in range(in_channels * out_channels)])\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return torch.cat([conv(x[:, i, :].unsqueeze(1)) for i, conv in enumerate(self.convs)], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YfViQv1-YWk"
      },
      "outputs": [],
      "source": [
        "class KAN_Convolutional_Layer_1D(torch.nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            in_channels: int = 1,\n",
        "            out_channels: int = 1,\n",
        "            kernel_size: int = 2,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            dilation: int = 1,\n",
        "            grid_size: int = 5,\n",
        "            spline_order: int = 3,\n",
        "            scale_noise: float = 0.1,\n",
        "            scale_base: float = 1.0,\n",
        "            scale_spline: float = 1.0,\n",
        "            base_activation=torch.nn.SiLU,\n",
        "            grid_eps: float = 0.02,\n",
        "            grid_range: tuple = [-1, 1],\n",
        "            device: str = \"cpu\"\n",
        "        ):\n",
        "        super(KAN_Convolutional_Layer_1D, self).__init__()\n",
        "        self.out_channels = out_channels\n",
        "        self.in_channels = in_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(in_channels * out_channels):\n",
        "            self.convs.append(\n",
        "                KAN_Convolution_1D(\n",
        "                    kernel_size=kernel_size,\n",
        "                    stride=stride,\n",
        "                    padding=padding,\n",
        "                    dilation=dilation,\n",
        "                    grid_size=grid_size,\n",
        "                    spline_order=spline_order,\n",
        "                    scale_noise=scale_noise,\n",
        "                    scale_base=scale_base,\n",
        "                    scale_spline=scale_spline,\n",
        "                    base_activation=base_activation,\n",
        "                    grid_eps=grid_eps,\n",
        "                    grid_range=grid_range,\n",
        "                )\n",
        "            )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        batch_size, in_channels, length = x.shape\n",
        "        output_length = (length + 2 * self.padding - self.dilation * (self.kernel_size - 1) - 1) // self.stride + 1\n",
        "        output = torch.zeros((batch_size, self.out_channels, output_length), device=x.device)\n",
        "\n",
        "\n",
        "        for i in range(self.out_channels):\n",
        "            output_accum = torch.zeros((batch_size, output_length), device=x.device)\n",
        "            for j in range(self.in_channels):\n",
        "                kernel_idx = i * self.in_channels + j\n",
        "                conv_result = self.convs[kernel_idx].forward(x[:, j, :].unsqueeze(1))\n",
        "                output_accum += conv_result.squeeze(1)  # Squeeze\n",
        "            output[:, i, :] = output_accum  # A to output channel\n",
        "\n",
        "        return output\n",
        "\n",
        "class KAN_Convolution_1D(torch.nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            kernel_size: int = 2,\n",
        "            stride: int = 1,\n",
        "            padding: int = 0,\n",
        "            dilation: int = 1,\n",
        "            grid_size: int = 50,\n",
        "            spline_order: int = 3,\n",
        "            scale_noise: float = 0.1,\n",
        "            scale_base: float = 1.0,\n",
        "            scale_spline: float = 1.0,\n",
        "            base_activation=torch.nn.SiLU,\n",
        "            grid_eps: float = 0.02,\n",
        "            grid_range: tuple = [-1, 1]\n",
        "        ):\n",
        "        super(KAN_Convolution_1D, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.conv = KANLinear(\n",
        "            in_features = kernel_size,\n",
        "            out_features = 1,\n",
        "            grid_size=grid_size,\n",
        "            spline_order=spline_order,\n",
        "            scale_noise=scale_noise,\n",
        "            scale_base=scale_base,\n",
        "            scale_spline=scale_spline,\n",
        "            base_activation=base_activation,\n",
        "            grid_eps=grid_eps,\n",
        "            grid_range=grid_range\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        self.device = x.device\n",
        "        return kan_conv1d(x, self.conv, self.kernel_size,self.stride, self.dilation, self.padding, self.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9TizKIdhhPg"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7BC_Xz3_5qM"
      },
      "outputs": [],
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, model_size):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.res_block = nn.Sequential(nn.ReLU(True),\n",
        "                                       nn.Conv1d(model_size, model_size, 5, padding=2),\n",
        "                                       nn.ReLU(True), nn.Conv1d(model_size, model_size, 5, padding=2))\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.res_block(input)\n",
        "        return input + 0.3 * output\n",
        "\n",
        "\n",
        "class WGANGenerator(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            model_size,\n",
        "            seq_len,\n",
        "            onehot_len,\n",
        "            last_channel_is_prob=False,\n",
        "    ):\n",
        "        super(WGANGenerator, self).__init__()\n",
        "\n",
        "        self.model_size = model_size\n",
        "        self.seq_len = 512\n",
        "        self.onehot_len = onehot_len\n",
        "        self.last_channel_is_prob = last_channel_is_prob\n",
        "        self.fc1 = KANLinear(128, self.model_size * self.seq_len)\n",
        "        # nn.Linear(128, self.model_size * self.seq_len)\n",
        "        self.block = nn.Sequential(ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size))\n",
        "        self.conv1 = nn.Conv1d(self.model_size, self.onehot_len, 1)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, noise):\n",
        "        output = self.fc1(noise)\n",
        "        output = output.view(-1, self.model_size, self.seq_len)\n",
        "        output = self.block(output)\n",
        "        output = self.conv1(output)\n",
        "        output = output.transpose(1, 2)\n",
        "        shape = output.size()\n",
        "        output = output.contiguous()\n",
        "        output = output.view(noise.shape[0] * self.seq_len, -1)\n",
        "        prob_channel = output.shape[-1]\n",
        "        if self.last_channel_is_prob:\n",
        "            prob_channel = -1\n",
        "            output1 = self.softmax(output[:, :prob_channel])\n",
        "            output2 = self.sigmoid(output[:, prob_channel]).view(output.shape[0], 1)\n",
        "            output = torch.cat((output1, output2), 1)\n",
        "        else:\n",
        "            output = self.softmax(output)\n",
        "        return output.view(shape)\n",
        "\n",
        "\n",
        "class WGANDiscriminator(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            model_size,\n",
        "            seq_len,\n",
        "            onehot_len,\n",
        "    ):\n",
        "        super(WGANDiscriminator, self).__init__()\n",
        "        self.model_size = model_size\n",
        "        self.seq_len = 512\n",
        "        self.onehot_len = onehot_len\n",
        "        self.block = nn.Sequential(ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size),\n",
        "                                   ResBlock(self.model_size))\n",
        "        self.conv1d = nn.Conv1d(self.onehot_len, self.model_size, 1)\n",
        "        self.linear = KANLinear(self.seq_len * self.model_size, 1)\n",
        "        # self.linear = nn.Linear(self.seq_len * self.model_size, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input.transpose(1, 2)\n",
        "        output = self.conv1d(output)\n",
        "        output = self.block(output)\n",
        "        output = output.view(-1, self.seq_len * self.model_size)\n",
        "        output = self.linear(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def load_wgan_generator(\n",
        "    filepath,\n",
        "    model_size=64,\n",
        "    num_channels=6,\n",
        "    latent_dim=100,\n",
        "    post_proc_filt_len=512,\n",
        "    upsample=True,\n",
        "    last_channel_is_prob=True,\n",
        "    **kwargs\n",
        "):\n",
        "    model = WGANGenerator(\n",
        "        model_size=model_size,\n",
        "        seq_len=post_proc_filt_len,\n",
        "        onehot_len=num_channels,\n",
        "        last_channel_is_prob=last_channel_is_prob,\n",
        "    )\n",
        "    model.load_state_dict(torch.load(filepath))\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_wgan_discriminator(\n",
        "        filepath,\n",
        "        model_size=64,\n",
        "        ngpus=1,\n",
        "        num_channels=6,\n",
        "        shift_factor=2,\n",
        "        alpha=0.2,\n",
        "        **kwargs\n",
        "):\n",
        "    model = WGANDiscriminator(model_size=model_size, ngpus=ngpus, num_channels=num_channels,\n",
        "                               shift_factor=shift_factor, alpha=alpha)\n",
        "    model.load_state_dict(torch.load(filepath))\n",
        "    return model\n",
        "\n",
        "\n",
        "# Save samles method\n",
        "def save_samples(\n",
        "        epoch_samples,\n",
        "        epoch,\n",
        "        output_dir,\n",
        "        model_gen,\n",
        "        model_dis,\n",
        "        last_channel_is_prob=True,\n",
        "):\n",
        "    \"\"\"\n",
        " Save output samples to disk\n",
        " \"\"\"\n",
        "    sample_dir = output_dir\n",
        "    if not os.path.exists(sample_dir):\n",
        "        os.makedirs(sample_dir)\n",
        "    samples = np.array(epoch_samples)\n",
        "    if last_channel_is_prob:\n",
        "        labels = np.take(samples, -1, axis=2)\n",
        "        samples = np.delete(samples, -1, axis=2)\n",
        "    seq = np.argmax(samples, axis=2)\n",
        "    df = pd.DataFrame(np.take(np.array(list(codes.keys())),\n",
        "                              indices=seq))\n",
        "    res = []\n",
        "    for i in range(len(seq)):\n",
        "        res.append(np.array(df.iloc[i]))\n",
        "        if last_channel_is_prob:\n",
        "            res.append(labels[i])\n",
        "    res_df = pd.DataFrame(res)\n",
        "    print(res_df)\n",
        "    res_path = os.path.join(sample_dir, '{}.csv'.format(epoch))\n",
        "    res_df.to_csv(res_path, index=False)\n",
        "    # save model\n",
        "    model_gen_output_path = os.path.join(sample_dir,\n",
        "                                         'model_gen_last.pkl')\n",
        "    model_dis_output_path = os.path.join(sample_dir,\n",
        "                                         'model_dis_last.pkl')\n",
        "    torch.save(model_gen.state_dict(), model_gen_output_path,\n",
        "               pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "    torch.save(model_dis.state_dict(), model_dis_output_path,\n",
        "               pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# Wasserstain training process\n",
        "LOGGER = logging.getLogger('g4gan')\n",
        "LOGGER.setLevel(logging.DEBUG)\n",
        "\n",
        "\n",
        "def compute_discr_loss_terms(\n",
        "        model_dis,\n",
        "        model_gen,\n",
        "        real_data_v,\n",
        "        noise_v,\n",
        "        batch_size,\n",
        "        latent_dim,\n",
        "        lmbda,\n",
        "        use_cuda,\n",
        "        use_binary_mask,\n",
        "        mask_v,\n",
        "        p_mask,\n",
        "        compute_grads=False,\n",
        "        last_channel_is_prob=True,\n",
        "):\n",
        "    # Convenient values for\n",
        "    one = torch.tensor(1, dtype=torch.float)\n",
        "    neg_one = one * -1\n",
        "    if use_cuda:\n",
        "        one = one.cuda()\n",
        "        neg_one = neg_one.cuda()\n",
        "    # Reset gradients\n",
        "    model_dis.zero_grad()\n",
        "    # Apply binary mask to real data\n",
        "    if use_binary_mask:\n",
        "        real_data_v = real_data_v  *  mask_v * (1 / p_mask)\n",
        "        if use_cuda:\n",
        "            real_data_v = real_data_v.cuda()\n",
        "        real_data_v = autograd.Variable(real_data_v)\n",
        "    # a) Compute loss contribution from real training data and backprop\n",
        "    # (negative of the empirical mean, w.r.t. the data distribution, of the discr.output)\n",
        "    D_real = model_dis(real_data_v)\n",
        "    D_real = D_real.mean()\n",
        "    # Negate since we want to _maximize_ this quantity\n",
        "    if compute_grads:\n",
        "        D_real.backward(neg_one)\n",
        "    # b) Compute loss contribution from generated data and backprop\n",
        "    # (empirical mean, w.r.t. the generator distribution, of the discr. output)\n",
        "    # Generate noise in latent space\n",
        "    # Generate data by passing noise through the generator\n",
        "    fake = autograd.Variable(model_gen(noise_v).data)\n",
        "    inputv = fake\n",
        "    # Apply binary mask to fake data\n",
        "    if use_binary_mask:\n",
        "        inputv = inputv *  mask_v * (1 / p_mask)\n",
        "        if use_cuda:\n",
        "            inputv = inputv.cuda()\n",
        "        inputv = autograd.Variable(inputv)\n",
        "    D_fake = model_dis(inputv)\n",
        "    D_fake = D_fake.mean()\n",
        "    if compute_grads:\n",
        "        D_fake.backward(one)\n",
        "    # c) Compute gradient penalty and backprop\n",
        "    gradient_penalty = calc_gradient_penalty(model_dis,\n",
        "                                             real_data_v.data,\n",
        "                                             fake.data,\n",
        "                                             batch_size,\n",
        "                                             lmbda,\n",
        "                                             use_cuda=use_cuda,\n",
        "                                             )\n",
        "    if compute_grads:\n",
        "        gradient_penalty.backward(one)\n",
        "    # Compute metrics and record in batch history\n",
        "    D_cost = D_fake - D_real + gradient_penalty\n",
        "    Wasserstein_D = D_real - D_fake\n",
        "    return (D_cost, Wasserstein_D)\n",
        "\n",
        "\n",
        "def compute_gener_loss_terms(\n",
        "        model_dis,\n",
        "        model_gen,\n",
        "        batch_size,\n",
        "        latent_dim,\n",
        "        use_cuda,\n",
        "        use_binary_mask,\n",
        "        mask_v,\n",
        "        p_mask,\n",
        "        compute_grads=False,\n",
        "        last_channel_is_prob=True,\n",
        "):\n",
        "    # Convenient values for\n",
        "    one = torch.tensor(1, dtype=torch.float)\n",
        "    neg_one = one * -1\n",
        "    if use_cuda:\n",
        "        one = one.cuda()\n",
        "        neg_one = neg_one.cuda()\n",
        "    # Reset generator gradients\n",
        "    model_gen.zero_grad()\n",
        "    # Sample from the generator\n",
        "    noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
        "    if use_cuda:\n",
        "        noise = noise.cuda()\n",
        "    noise_v = autograd.Variable(noise)\n",
        "    fake = model_gen(noise_v)\n",
        "    # Apply binary mask to fake data\n",
        "    if use_binary_mask:\n",
        "        fake = fake  * mask_v * (1 / p_mask)\n",
        "    if use_cuda:\n",
        "        fake = fake.cuda()\n",
        "    # Compute generator loss and backprop\n",
        "    # (negative of empirical mean (w.r.t generator distribution) of discriminator\n",
        "    G = model_dis(fake)\n",
        "    G = G.mean()\n",
        "\n",
        "    if compute_grads:\n",
        "        G.backward(neg_one)\n",
        "    G_cost = -G\n",
        "    return G_cost\n",
        "\n",
        "\n",
        "def np_to_input_var(data, use_cuda):\n",
        "    data = torch.Tensor(data)\n",
        "    if use_cuda:\n",
        "        data = data.cuda()\n",
        "    return autograd.Variable(data)\n",
        "\n",
        "\n",
        "# Adapted from https://github.com/caogang/wgan-gp/blob/master/gan_toy.py\n",
        "def calc_gradient_penalty(\n",
        "        model_dis,\n",
        "        real_data,\n",
        "        fake_data,\n",
        "        batch_size,\n",
        "        lmbda,\n",
        "        use_cuda=True,\n",
        "):\n",
        "    # Compute interpolation factors\n",
        "    alpha = torch.rand(batch_size, 1, 1)\n",
        "    alpha = alpha.expand(real_data.size())\n",
        "    alpha = (alpha.cuda() if use_cuda else alpha)\n",
        "    # Interpolate between real and fake data\n",
        "    interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
        "    if use_cuda:\n",
        "        interpolates = interpolates.cuda()\n",
        "    interpolates = autograd.Variable(interpolates, requires_grad=True)\n",
        "    # Evaluate discriminator\n",
        "    disc_interpolates = model_dis(interpolates)\n",
        "    # Obtain gradients of the discriminator with respect to the inputs\n",
        "    gradients = autograd.grad(\n",
        "        outputs=disc_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=(torch.ones(disc_interpolates.size()).cuda() if use_cuda else\n",
        "                      torch.ones(disc_interpolates.size())),\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    # Compute MSE between 1.0 and the gradient of the norm penalty to encourage\n",
        "\n",
        "    # to be a 1-Lipschitz function\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() \\\n",
        "                       * lmbda\n",
        "    return gradient_penalty"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30vHGv1uIuDh",
        "outputId": "9be4fd70-8938-4531-b55f-8910c40f0e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta5sp_dxTOyi"
      },
      "outputs": [],
      "source": [
        "def train_wgan(\n",
        "        model_gen,\n",
        "        model_dis,\n",
        "        train_gen,\n",
        "        valid_gen,\n",
        "        test_data,\n",
        "        num_epochs,\n",
        "        batches_per_epoch,\n",
        "        batch_size,\n",
        "        output_dir=None,\n",
        "        lmbda=0.1,\n",
        "        use_cuda=True,\n",
        "        discriminator_updates=5,\n",
        "        epochs_per_sample=10,\n",
        "        sample_size=20,\n",
        "        lr=1e-4,\n",
        "        beta_1=0.5,\n",
        "        beta_2=0.9,\n",
        "        latent_dim=100,\n",
        "        use_knn_score=False,\n",
        "        knn_score_sample_size=1000,\n",
        "        knn_score_real_data=None,\n",
        "        use_binary_mask=False,\n",
        "        start_p_mask=1,\n",
        "        mask_end_epoch=100,\n",
        "        last_channel_is_prob=True,\n",
        "):\n",
        "    if use_cuda:\n",
        "        model_gen = model_gen.cuda()\n",
        "        model_dis = model_dis.cuda()\n",
        "    # Initialize optimizers for each model\n",
        "    optimizer_gen = optim.Adam(model_gen.parameters(), lr=lr,\n",
        "                               betas=(beta_1, beta_2))\n",
        "    optimizer_dis = optim.Adam(model_dis.parameters(), lr=lr,\n",
        "                               betas=(beta_1, beta_2))\n",
        "    # Sample noise used for seeing the evolution of generated output samples\n",
        "\n",
        "    sample_noise = torch.Tensor(sample_size, latent_dim).uniform_(-1, 1)\n",
        "    if use_cuda:\n",
        "        sample_noise = sample_noise.cuda()\n",
        "    sample_noise_v = autograd.Variable(sample_noise)\n",
        "    samples = {}\n",
        "    history = []\n",
        "    plot_history = []\n",
        "    plot_knn_score_history = []\n",
        "    train_iter = iter(train_gen)\n",
        "    valid_iter = iter(valid_gen)\n",
        "    test_data_v = np_to_input_var(test_data, use_cuda)\n",
        "    # Sample noise for KNN\n",
        "    if use_knn_score and knn_score_real_data is not None:\n",
        "        LOGGER.info('Create KDTree')\n",
        "        X = np.argmax(knn_score_real_data, 2)\n",
        "\n",
        "        knn_tree = NearestNeighbors(n_neighbors=2, algorithm='auto',\n",
        "                                    metric=lambda a, b: \\\n",
        "                                        editdistance.eval(a, b))\n",
        "        knn_tree.fit(X)\n",
        "        knn_sample_noise = torch.Tensor(knn_score_sample_size,\n",
        "                                        latent_dim).uniform_(-1, 1)\n",
        "        if use_cuda:\n",
        "            knn_sample_noise = knn_sample_noise.cuda()\n",
        "        knn_sample_noise_v = autograd.Variable(knn_sample_noise)\n",
        "        # Score on train data\n",
        "        (dist, ind) = knn_tree.kneighbors(X[:], 2)\n",
        "        d_self = np.mean(np.take(dist, 1, axis=1))\n",
        "        d_train = np.mean(np.take(dist, 0, axis=1))\n",
        "        LOGGER.info('KNN score on train data:')\n",
        "        LOGGER.info('D_self: {}'.format(d_self))\n",
        "        LOGGER.info('D_train: {}'.format(d_train))\n",
        "        Y = np.argmax(test_data, 2)\n",
        "        knn_self_tree = NearestNeighbors(n_neighbors=2, algorithm='auto'\n",
        "                                         , metric=lambda a, b: editdistance.eval(a, b))\n",
        "        knn_self_tree.fit(Y)\n",
        "        (dist, ind) = knn_self_tree.kneighbors(Y[:], 2)\n",
        "        d_self = np.mean(np.take(dist, 1, axis=1))\n",
        "        (dist, ind) = knn_tree.kneighbors(Y[:], 1)\n",
        "        d_train = np.mean(np.take(dist, 0, axis=1))\n",
        "        LOGGER.info('KNN score on test data:')\n",
        "        LOGGER.info('D_self: {}'.format(d_self))\n",
        "        LOGGER.info('D_train: {}'.format(d_train))\n",
        "        best_self_knn_score = 0\n",
        "    # Set p_mask\n",
        "    p_mask = None\n",
        "    mask_v = 0.1\n",
        "    if use_binary_mask:\n",
        "        p_mask = start_p_mask\n",
        "        LOGGER.info('Setup p_mask: {}'.format(p_mask))\n",
        "\n",
        "\n",
        "    # Loop over the dataset multiple times\n",
        "    for epoch in range(num_epochs):\n",
        "        LOGGER.info('Epoch: {}/{}'.format(epoch + 1, num_epochs))\n",
        "        epoch_history = []\n",
        "        for batch_idx in range(batches_per_epoch):\n",
        "            # Set model parameters to require gradients to be computed and stored\n",
        "            for p in model_dis.parameters():\n",
        "                p.requires_grad = True\n",
        "            # Initialize the metrics for this batch\n",
        "            batch_history = {'discriminator': [], 'generator': {}}\n",
        "            # Discriminator Training Phase:\n",
        "\n",
        "            # -> Train discriminator k times\n",
        "            for iter_d in range(discriminator_updates):\n",
        "                # Get real examples\n",
        "                real_data_v = np_to_input_var(next(train_iter),\n",
        "                                              use_cuda)\n",
        "                # Get valid examples\n",
        "                valid_data_v = np_to_input_var(next(valid_iter),\n",
        "                                               use_cuda)\n",
        "                # Get noise\n",
        "                noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
        "                if use_cuda:\n",
        "                    noise = noise.cuda()\n",
        "                noise_v = autograd.Variable(noise, volatile=True)  # totally freeze model_gen\n",
        "    # Get new batch of real training data\n",
        "                (D_cost_train, D_wass_train) = compute_discr_loss_terms(\n",
        "                    model_dis,\n",
        "                    model_gen,\n",
        "                    real_data_v,\n",
        "                    noise_v,\n",
        "                    batch_size,\n",
        "                    latent_dim,\n",
        "                    lmbda,\n",
        "                    use_cuda,\n",
        "                    use_binary_mask,\n",
        "                    mask_v,\n",
        "                    p_mask,\n",
        "                    compute_grads=True,\n",
        "                    last_channel_is_prob=last_channel_is_prob,\n",
        "                )\n",
        "                # Update the discriminator\n",
        "                optimizer_dis.step()\n",
        "                (D_cost_valid, D_wass_valid) = compute_discr_loss_terms(\n",
        "                    model_dis,\n",
        "                    model_gen,\n",
        "                    valid_data_v,\n",
        "                    noise_v,\n",
        "                    batch_size,\n",
        "                    latent_dim,\n",
        "                    lmbda,\n",
        "                    use_cuda,\n",
        "                    use_binary_mask,\n",
        "                    mask_v,\n",
        "                    p_mask,\n",
        "                    compute_grads=False,\n",
        "                    last_channel_is_prob=last_channel_is_prob,\n",
        "                )\n",
        "                if use_cuda:\n",
        "                    D_cost_train = D_cost_train.cpu()\n",
        "                    D_cost_valid = D_cost_valid.cpu()\n",
        "                    D_wass_train = D_wass_train.cpu()\n",
        "                    D_wass_valid = D_wass_valid.cpu()\n",
        "\n",
        "                batch_history['discriminator'].append({\n",
        "                    'cost': float(D_cost_train.data.numpy()),\n",
        "                    'wasserstein_cost':\n",
        "                        float(D_wass_train.data.numpy()),\n",
        "                    'cost_validation':\n",
        "                        float(D_cost_valid.data.numpy()),\n",
        "                    'wasserstein_cost_validation':\n",
        "                        float(D_wass_valid.data.numpy()),\n",
        "                })\n",
        "            # ###########################\n",
        "            # (2) Update G network\n",
        "            # ##########################\n",
        "            # Prevent discriminator from computing gradients, since\n",
        "            # we are only updating the generator\n",
        "            for p in model_dis.parameters():\n",
        "                p.requires_grad = False\n",
        "            G_cost = compute_gener_loss_terms(\n",
        "                model_dis,\n",
        "                model_gen,\n",
        "                batch_size,\n",
        "                latent_dim,\n",
        "                use_cuda,\n",
        "                use_binary_mask,\n",
        "                mask_v,\n",
        "                p_mask,\n",
        "                compute_grads=True,\n",
        "                last_channel_is_prob=last_channel_is_prob,\n",
        "            )\n",
        "            # Update generator\n",
        "            optimizer_gen.step()\n",
        "            if use_cuda:\n",
        "                G_cost = G_cost.cpu()\n",
        "            # Record generator loss\n",
        "            batch_history['generator']['cost'] = \\\n",
        "                float(G_cost.data.numpy())\n",
        "            # Record batch metrics\n",
        "            epoch_history.append(batch_history)\n",
        "      # Update binary mask\n",
        "        if use_binary_mask:\n",
        "            next_epoch = epoch + 1\n",
        "            p_mask = (1 - start_p_mask) / mask_end_epoch * next_epoch \\\n",
        "                    + start_p_mask\n",
        "\n",
        "            if next_epoch == mask_end_epoch or p_mask > 1.:\n",
        "                p_mask = 1.\n",
        "            LOGGER.info('Update p_mask: {}'.format(p_mask))\n",
        "        # Record epoch metrics\n",
        "        history.append(epoch_history)\n",
        "        LOGGER.info(pprint.pformat(epoch_history[-1]))\n",
        "        # Plot\n",
        "        plot_history.append(epoch_history[-1]['discriminator'][-1])\n",
        "        plot_history[-1]['gen_cost'] = epoch_history[-1]['generator'\n",
        "        ]['cost']\n",
        "        pd.DataFrame(plot_history).plot()\n",
        "        plt.show()\n",
        "    # Calc KNN score\n",
        "        if use_knn_score and knn_tree is not None:\n",
        "            LOGGER.info('Calculate KNN score...')\n",
        "            # Self KNN score (D_self)\n",
        "            knn_samp_output = model_gen(knn_sample_noise_v)\n",
        "            if use_cuda:\n",
        "                knn_samp_output = knn_samp_output.cpu()\n",
        "            # One hot\n",
        "            prob_channel = knn_samp_output.shape[2]\n",
        "            if last_channel_is_prob:\n",
        "                prob_channel = -1\n",
        "            (values, indices) = knn_samp_output[:, :, :\n",
        "                                                      prob_channel].max(2)\n",
        "            knn_samp_output[:, :, :prob_channel] = 0\n",
        "            indices = indices.view(indices.shape[0], indices.shape[1],\n",
        "                                  1)\n",
        "            knn_samp_output = knn_samp_output.scatter_(2, indices, 1)\n",
        "            knn_samp_output = knn_samp_output.data.numpy()\n",
        "            Y = np.argmax(knn_samp_output, 2)\n",
        "            knn_self_tree = NearestNeighbors(n_neighbors=2,\n",
        "                                            algorithm='auto', metric=lambda a, b: \\\n",
        "                    editdistance.eval(a, b))\n",
        "            knn_self_tree.fit(Y)\n",
        "            (dist, ind) = knn_self_tree.kneighbors(Y[:], 2)\n",
        "            d_self = np.mean(np.take(dist, 1, axis=1))\n",
        "            # Train KNN score\n",
        "            (dist, ind) = knn_tree.kneighbors(Y[:], 1)\n",
        "            d_train = np.mean(np.take(dist, 0, axis=1))\n",
        "            # History and plot\n",
        "            LOGGER.info('D_self: {}'.format(d_self))\n",
        "            LOGGER.info('D_train: {}'.format(d_train))\n",
        "            plot_knn_score_history.append({'d_self': d_self,\n",
        "                                          'd_train': d_train})\n",
        "            pd.DataFrame(plot_knn_score_history).plot()\n",
        "\n",
        "            plt.show()\n",
        "            # Save best knn self score model\n",
        "            if output_dir and d_self > best_self_knn_score:\n",
        "                best_self_knn_score = d_self\n",
        "                # save model\n",
        "                model_gen_output_path = os.path.join(output_dir,\n",
        "\n",
        "                                                    'model_gen_best_knn_self_{}.pkl'.format(int(best_self_knn_score)))\n",
        "                model_dis_output_path = os.path.join(output_dir,\n",
        "\n",
        "                                                    'model_dis_best_knn_self_{}.pkl'.format(int(best_self_knn_score)))\n",
        "                torch.save(model_gen.state_dict(),\n",
        "                          model_gen_output_path,\n",
        "                          pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "                torch.save(model_dis.state_dict(),\n",
        "                          model_dis_output_path,\n",
        "                          pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "        if (epoch + 1) % epochs_per_sample == 0:\n",
        "            # Generate outputs for fixed latent samples\n",
        "            LOGGER.info('Generating samples...')\n",
        "            samp_output = model_gen(sample_noise_v)\n",
        "            if use_cuda:\n",
        "                samp_output = samp_output.cpu()\n",
        "            samples[epoch + 1] = samp_output.data.numpy()\n",
        "            if output_dir:\n",
        "                LOGGER.info('Saving samples...')\n",
        "                save_samples(\n",
        "                    samples[epoch + 1],\n",
        "                    epoch + 1,\n",
        "                    output_dir,\n",
        "                    model_gen,\n",
        "                    model_dis,\n",
        "                    last_channel_is_prob=last_channel_is_prob,\n",
        "                )\n",
        "    # # Get final discriminator loss\n",
        "    # Get noise\n",
        "    noise = torch.Tensor(batch_size, latent_dim).uniform_(-1, 1)\n",
        "    if use_cuda:\n",
        "        noise = noise.cuda()\n",
        "    noise_v = autograd.Variable(noise, volatile=True)  # totally freeze generator\n",
        "    final_discr_metrics = {\n",
        "        'cost_validation': 0,\n",
        "        'wasserstein_cost_validation': 0,\n",
        "        'cost_test': 0,\n",
        "        'wasserstein_cost_test': 0,\n",
        "    }\n",
        "    return model_gen, model_dis, history, final_discr_metrics, samples\n",
        "\n",
        "\n",
        "# Batch generator\n",
        "\n",
        "def batch_generator(data, batch_size, shuffle_each_epoch=True):\n",
        "    indices = np.arange(data.shape[0])\n",
        "    batch = []\n",
        "    while True:\n",
        "        if shuffle_each_epoch:\n",
        "            np.random.shuffle(indices)\n",
        "        for i in indices:\n",
        "            batch.append(i)\n",
        "            if len(batch) == batch_size:\n",
        "                yield data[batch]\n",
        "                batch = []\n",
        "\n",
        "\n",
        "def create_data_split(\n",
        "        g4_np_dataset_path,\n",
        "        valid_ratio,\n",
        "        test_ratio,\n",
        "        train_batch_size,\n",
        "        shuffle_each_epoch=True,\n",
        "        train_subset_size=100,\n",
        "):\n",
        "    data = np.load(g4_np_dataset_path)\n",
        "    num_g4 = data.shape[0]\n",
        "    num_valid = int(np.ceil(num_g4 * valid_ratio))\n",
        "    num_test = int(np.ceil(num_g4 * test_ratio))\n",
        "    num_train = num_g4 - num_valid - num_test\n",
        "    assert num_valid > 0\n",
        "    assert num_test > 0\n",
        "    assert num_train > 0\n",
        "    indices = np.arange(num_g4)\n",
        "    np.random.shuffle(indices)\n",
        "    train_data_indices = indices[:num_train]\n",
        "    valid_data_indices = indices[num_train:num_train + num_valid]\n",
        "    test_data_indices = indices[num_train + num_valid:]\n",
        "    train_data = data[train_data_indices]\n",
        "    valid_data = data[valid_data_indices]\n",
        "    test_data = data[test_data_indices]\n",
        "    train_gen = batch_generator(train_data, train_batch_size,\n",
        "                                shuffle_each_epoch)\n",
        "    valid_gen = batch_generator(valid_data, train_batch_size,\n",
        "                                shuffle_each_epoch)\n",
        "    train_subset = None\n",
        "    if train_subset_size > 0:\n",
        "        train_subset = train_data[:train_subset_size]\n",
        "    return (train_gen, valid_gen, test_data, train_subset)\n",
        "\n",
        "\n",
        "# Log\n",
        "def init_console_logger(logger, verbose=False):\n",
        "    # Log to stderr also\n",
        "    stream_handler = logging.StreamHandler()\n",
        "    if verbose:\n",
        "        stream_handler.setLevel(logging.DEBUG)\n",
        "    else:\n",
        "        stream_handler.setLevel(logging.INFO)\n",
        "    formatter = \\\n",
        "        logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        "                          )\n",
        "    stream_handler.setFormatter(formatter)\n",
        "    logger.addHandler(stream_handler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7en4jlgdjF1D"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spEyoe45jWOK"
      },
      "outputs": [],
      "source": [
        "# raw_dataset.to_csv(\"/content/drive/My Drive/Zdna.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Train\n",
        "# path = 'G4_Chip_seq_quadruplex_norm_quad_labeled.npy'\n",
        "# channels = 6\n",
        "# last_channel_is_prob = True\n",
        "# path = '/content/G4_Chip_seq_quadruplex_norm_quad_labeled.npy'\n",
        "# path = '/content/WuKou_zdna2016_filter-norm_to_512.npy'\n",
        "path = \"/content/zdna2016_norm_quad_labeled.npy\"\n",
        "channels = 6\n",
        "last_channel_is_prob = True\n",
        "args = {}\n",
        "args['verbose'] = True\n",
        "args['batches_per_epoch'] = 109\n",
        "args['batch_size'] = 64\n",
        "args['latent_dim'] = 128\n",
        "args['ngpus'] = 1\n",
        "args['model_size'] = 32\n",
        "args['output_dir'] = 'models/'\n",
        "args['g4_np_data_path'] = path\n",
        "args['valid_ratio'] = 0.1\n",
        "args['test_ratio'] = 0.1\n",
        "args['shuffle_train_each_epoch'] = True\n",
        "args['post_proc_filt_len'] = None\n",
        "args['alpha'] = 0.2\n",
        "args['shift_factor'] = 2\n",
        "args['batch_shuffle'] = False\n",
        "args['num_epochs'] = 200\n",
        "args['learning_rate'] = 1e-4\n",
        "args['beta1'] = 0.5\n",
        "args['beta2'] = 0.9\n",
        "args['lmbda'] = 10.0\n",
        "args['discriminator_updates'] = 5\n",
        "args['epochs_per_sample'] = 5\n",
        "args['sample_size'] = 20\n",
        "args['num_channels'] = channels\n",
        "args['use_knn_score'] = True\n",
        "args['knn_score_sample_size'] = 100\n",
        "args['use_binary_mask'] = False\n",
        "args['start_p_mask'] = 0.3\n",
        "args['mask_end_epoch'] = 90\n",
        "args['last_channel_is_prob'] = last_channel_is_prob\n",
        "init_console_logger(LOGGER, args['verbose'])\n",
        "LOGGER.info('Initialized logger.')\n",
        "batch_size = args['batch_size']\n",
        "latent_dim = args['latent_dim']\n",
        "ngpus = args['ngpus']\n",
        "model_size = args['model_size']\n",
        "model_dir = os.path.join(args['output_dir'],\n",
        "                         datetime.datetime.now().strftime('%Y%m%d%H%M%S'\n",
        "                                                          ))\n",
        "args['model_dir'] = model_dir\n",
        "if not args['use_knn_score']:\n",
        "    args['knn_score_sample_size'] = 0\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "LOGGER.info('Saving configurations...')\n",
        "config_path = os.path.join(model_dir, 'config.json')\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(args, f)\n",
        "LOGGER.info('Loading G4 data...')\n",
        "g4_np_data_path = args['g4_np_data_path']\n",
        "(train_gen, valid_gen, test_data, train_subset) = create_data_split(\n",
        "    g4_np_data_path,\n",
        "    args['valid_ratio'],\n",
        "    args['test_ratio'],\n",
        "    batch_size,\n",
        "    args['shuffle_train_each_epoch'],\n",
        "    args['knn_score_sample_size'],\n",
        ")\n",
        "LOGGER.info('Creating models...')\n",
        "model_gen = WGANGenerator(args['model_size'], 512, args['num_channels'\n",
        "],\n",
        "                           last_channel_is_prob=args['last_channel_is_prob'\n",
        "                           ])\n",
        "model_dis = WGANDiscriminator(args['model_size'], 512,\n",
        "                               args['num_channels'])\n",
        "LOGGER.info(model_gen)\n",
        "LOGGER.info(model_dis)\n",
        "LOGGER.info('Starting training...')\n",
        "(model_gen, model_dis, history, final_discr_metrics, samples) = \\\n",
        "    train_wgan(\n",
        "        model_gen=model_gen,\n",
        "        model_dis=model_dis,\n",
        "        train_gen=train_gen,\n",
        "        valid_gen=valid_gen,\n",
        "        test_data=test_data,\n",
        "        num_epochs=args['num_epochs'],\n",
        "        batches_per_epoch=args['batches_per_epoch'],\n",
        "        batch_size=batch_size,\n",
        "        output_dir=model_dir,\n",
        "        lr=args['learning_rate'],\n",
        "        beta_1=args['beta1'],\n",
        "        beta_2=args['beta2'],\n",
        "        lmbda=args['lmbda'],\n",
        "        use_cuda=ngpus >= 1,\n",
        "        discriminator_updates=args['discriminator_updates'],\n",
        "        latent_dim=latent_dim,\n",
        "        epochs_per_sample=args['epochs_per_sample'],\n",
        "        sample_size=args['sample_size'],\n",
        "\n",
        "        use_knn_score=args['use_knn_score'],\n",
        "        knn_score_sample_size=args['knn_score_sample_size'],\n",
        "        knn_score_real_data=train_subset,\n",
        "        use_binary_mask=args['use_binary_mask'],\n",
        "        start_p_mask=args['start_p_mask'],\n",
        "        mask_end_epoch=args['mask_end_epoch'],\n",
        "        last_channel_is_prob=args['last_channel_is_prob'],\n",
        "    )\n",
        "LOGGER.info('Finished training.')\n",
        "LOGGER.info('Final discriminator loss on validation and test:')\n",
        "LOGGER.info(pprint.pformat(final_discr_metrics))\n",
        "LOGGER.info('Saving models...')\n",
        "model_gen_output_path = os.path.join(model_dir, 'model_gen.pkl')\n",
        "model_dis_output_path = os.path.join(model_dir, 'model_dis.pkl')\n",
        "torch.save(model_gen.state_dict(), model_gen_output_path,\n",
        "           pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "torch.save(model_dis.state_dict(), model_dis_output_path,\n",
        "           pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "LOGGER.info('Saving metrics...')\n",
        "history_output_path = os.path.join(model_dir, 'history.pkl')\n",
        "final_discr_metrics_output_path = os.path.join(model_dir,\n",
        "                                               'final_discr_metrics.pkl')\n",
        "with open(history_output_path, 'wb') as f:\n",
        "    pk.dump(history, f)\n",
        "with open(final_discr_metrics_output_path, 'wb') as f:\n",
        "    pk.dump(final_discr_metrics, f)\n",
        "LOGGER.info('Done with LKAN!')"
      ],
      "metadata": {
        "id": "Idey9JRktDAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(p.numel() for p in model_gen.parameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WPYAKARJMoV",
        "outputId": "b166d0e1-5740-4deb-e201-3de8372c4ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21023238"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9VlImqT9TWJ4"
      },
      "outputs": [],
      "source": [
        "# # Train\n",
        "# path = 'G4_Chip_seq_quadruplex_norm_quad_labeled.npy'\n",
        "# channels = 6\n",
        "# last_channel_is_prob = True\n",
        "# path = '/content/G4_Chip_seq_quadruplex_norm_quad_labeled.npy'\n",
        "# path = '/content/WuKou_zdna2016_filter-norm_to_512.npy'\n",
        "path = \"/content/zdna2016_norm_quad_labeled.npy\"\n",
        "channels = 6\n",
        "last_channel_is_prob = True\n",
        "args = {}\n",
        "args['verbose'] = True\n",
        "args['batches_per_epoch'] = 109\n",
        "args['batch_size'] = 64\n",
        "args['latent_dim'] = 128\n",
        "args['ngpus'] = 1\n",
        "args['model_size'] = 32\n",
        "args['output_dir'] = 'models/'\n",
        "args['g4_np_data_path'] = path\n",
        "args['valid_ratio'] = 0.1\n",
        "args['test_ratio'] = 0.1\n",
        "args['shuffle_train_each_epoch'] = True\n",
        "args['post_proc_filt_len'] = None\n",
        "args['alpha'] = 0.2\n",
        "args['shift_factor'] = 2\n",
        "args['batch_shuffle'] = False\n",
        "args['num_epochs'] = 200\n",
        "args['learning_rate'] = 1e-4\n",
        "args['beta1'] = 0.5\n",
        "args['beta2'] = 0.9\n",
        "args['lmbda'] = 10.0\n",
        "args['discriminator_updates'] = 5\n",
        "args['epochs_per_sample'] = 5\n",
        "args['sample_size'] = 20\n",
        "args['num_channels'] = channels\n",
        "args['use_knn_score'] = True\n",
        "args['knn_score_sample_size'] = 100\n",
        "args['use_binary_mask'] = False\n",
        "args['start_p_mask'] = 0.3\n",
        "args['mask_end_epoch'] = 90\n",
        "args['last_channel_is_prob'] = last_channel_is_prob\n",
        "init_console_logger(LOGGER, args['verbose'])\n",
        "LOGGER.info('Initialized logger.')\n",
        "batch_size = args['batch_size']\n",
        "latent_dim = args['latent_dim']\n",
        "ngpus = args['ngpus']\n",
        "model_size = args['model_size']\n",
        "model_dir = os.path.join(args['output_dir'],\n",
        "                         datetime.datetime.now().strftime('%Y%m%d%H%M%S'\n",
        "                                                          ))\n",
        "args['model_dir'] = model_dir\n",
        "if not args['use_knn_score']:\n",
        "    args['knn_score_sample_size'] = 0\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "LOGGER.info('Saving configurations...')\n",
        "config_path = os.path.join(model_dir, 'config.json')\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(args, f)\n",
        "LOGGER.info('Loading G4 data...')\n",
        "g4_np_data_path = args['g4_np_data_path']\n",
        "(train_gen, valid_gen, test_data, train_subset) = create_data_split(\n",
        "    g4_np_data_path,\n",
        "    args['valid_ratio'],\n",
        "    args['test_ratio'],\n",
        "    batch_size,\n",
        "    args['shuffle_train_each_epoch'],\n",
        "    args['knn_score_sample_size'],\n",
        ")\n",
        "LOGGER.info('Creating models...')\n",
        "model_gen = WGANGenerator(args['model_size'], 512, args['num_channels'\n",
        "],\n",
        "                           last_channel_is_prob=args['last_channel_is_prob'\n",
        "                           ])\n",
        "model_dis = WGANDiscriminator(args['model_size'], 512,\n",
        "                               args['num_channels'])\n",
        "LOGGER.info(model_gen)\n",
        "LOGGER.info(model_dis)\n",
        "LOGGER.info('Starting training...')\n",
        "(model_gen, model_dis, history, final_discr_metrics, samples) = \\\n",
        "    train_wgan(\n",
        "        model_gen=model_gen,\n",
        "        model_dis=model_dis,\n",
        "        train_gen=train_gen,\n",
        "        valid_gen=valid_gen,\n",
        "        test_data=test_data,\n",
        "        num_epochs=args['num_epochs'],\n",
        "        batches_per_epoch=args['batches_per_epoch'],\n",
        "        batch_size=batch_size,\n",
        "        output_dir=model_dir,\n",
        "        lr=args['learning_rate'],\n",
        "        beta_1=args['beta1'],\n",
        "        beta_2=args['beta2'],\n",
        "        lmbda=args['lmbda'],\n",
        "        use_cuda=ngpus >= 1,\n",
        "        discriminator_updates=args['discriminator_updates'],\n",
        "        latent_dim=latent_dim,\n",
        "        epochs_per_sample=args['epochs_per_sample'],\n",
        "        sample_size=args['sample_size'],\n",
        "\n",
        "        use_knn_score=args['use_knn_score'],\n",
        "        knn_score_sample_size=args['knn_score_sample_size'],\n",
        "        knn_score_real_data=train_subset,\n",
        "        use_binary_mask=args['use_binary_mask'],\n",
        "        start_p_mask=args['start_p_mask'],\n",
        "        mask_end_epoch=args['mask_end_epoch'],\n",
        "        last_channel_is_prob=args['last_channel_is_prob'],\n",
        "    )\n",
        "LOGGER.info('Finished training.')\n",
        "LOGGER.info('Final discriminator loss on validation and test:')\n",
        "LOGGER.info(pprint.pformat(final_discr_metrics))\n",
        "LOGGER.info('Saving models...')\n",
        "model_gen_output_path = os.path.join(model_dir, 'model_gen.pkl')\n",
        "model_dis_output_path = os.path.join(model_dir, 'model_dis.pkl')\n",
        "torch.save(model_gen.state_dict(), model_gen_output_path,\n",
        "           pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "torch.save(model_dis.state_dict(), model_dis_output_path,\n",
        "           pickle_protocol=pk.HIGHEST_PROTOCOL)\n",
        "LOGGER.info('Saving metrics...')\n",
        "history_output_path = os.path.join(model_dir, 'history.pkl')\n",
        "final_discr_metrics_output_path = os.path.join(model_dir,\n",
        "                                               'final_discr_metrics.pkl')\n",
        "with open(history_output_path, 'wb') as f:\n",
        "    pk.dump(history, f)\n",
        "with open(final_discr_metrics_output_path, 'wb') as f:\n",
        "    pk.dump(final_discr_metrics, f)\n",
        "LOGGER.info('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD5bogO5BUFp"
      },
      "source": [
        "# Reconstruct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAA0v6ctXMQ-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.parallel\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import sklearn.metrics as metrics\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i0u1JozEbGC"
      },
      "outputs": [],
      "source": [
        "codes = {\n",
        " 'A': [1., 0., 0., 0., 0.],\n",
        " 'T': [0., 1., 0., 0., 0.],\n",
        " 'G': [0., 0., 1., 0., 0.],\n",
        " 'C': [0., 0., 0., 1., 0.],\n",
        " 'N': [0., 0., 0., 0., 1.],\n",
        " }\n",
        "\n",
        "quad_len = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbJAyHHqkqIZ"
      },
      "outputs": [],
      "source": [
        "one_hot_quads = []\n",
        "line_num = 0\n",
        "with open(\"/content/drive/My Drive/data_for_gans/preprocessed_fastas/mmHDNA_filter-norm_to_500.fasta\", 'r') as f:\n",
        "  for line in f:\n",
        "    if line[0] != '>':\n",
        "      one_hot = []\n",
        "      for s in line.upper():\n",
        "        if s != '\\n':\n",
        "          one_hot.append(codes[s])\n",
        "      one_hot_quads.append(one_hot)\n",
        "      line_num += 1\n",
        "one_hot_quads_np = np.array(one_hot_quads)\n",
        "np.save('mmHDNA_filter-norm_to_500.npy', one_hot_quads_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwvPfoDA8T9C"
      },
      "outputs": [],
      "source": [
        "one_hot_quads = []\n",
        "line_num = 0\n",
        "with open(\"/content/drive/My Drive/data_for_gans/preprocessed_fastas/mmQuad_filter-norm_to_500.fasta\", 'r') as f:\n",
        "  for line in f:\n",
        "    if line[0] != '>':\n",
        "      one_hot = []\n",
        "      for s in line.upper():\n",
        "        if s != '\\n':\n",
        "          one_hot.append(codes[s])\n",
        "      one_hot_quads.append(one_hot)\n",
        "      line_num += 1\n",
        "one_hot_quads_np = np.array(one_hot_quads)\n",
        "np.save('mmQuad_filter-norm_to_500.npy', one_hot_quads_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQHrwYGH8UAK"
      },
      "outputs": [],
      "source": [
        "# one_hot_quads = []\n",
        "# line_num = 0\n",
        "# with open('/content/drive/My Drive/data_for_gans/preprocessed_fastas/WuKou2016_filter-norm_to_512.fasta', 'r') as f:\n",
        "#   for line in f:\n",
        "#     if line[0] != '>':\n",
        "#       one_hot = []\n",
        "#       for s in line.upper():\n",
        "#         if s != '\\n':\n",
        "#           one_hot.append(codes[s])\n",
        "#       one_hot_quads.append(one_hot)\n",
        "#       line_num += 1\n",
        "# one_hot_quads_np = np.array(one_hot_quads)\n",
        "# np.save('WuKou2016_filter-norm_to_500.npy', one_hot_quads_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K94xoaoM8l6t"
      },
      "outputs": [],
      "source": [
        "# one_hot_quads = []\n",
        "# line_num = 0\n",
        "# with open('/content/drive/My Drive/data_for_gans/preprocessed_fastas/zdna2016_filter-norm_to_512.fasta', 'r') as f:\n",
        "#   for line in f:\n",
        "#     if line[0] != '>':\n",
        "#       one_hot = []\n",
        "#       for s in line.upper():\n",
        "#         if s != '\\n':\n",
        "#           one_hot.append(codes[s])\n",
        "#       one_hot_quads.append(one_hot)\n",
        "#       line_num += 1\n",
        "# one_hot_quads_np = np.array(one_hot_quads)\n",
        "# np.save('zdna2016_filter-norm_to_500.npy', one_hot_quads_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDcp5aQ187u1"
      },
      "outputs": [],
      "source": [
        "data1 = np.load(\"/content/mmHDNA_filter-norm_to_500.npy\")\n",
        "data2 = np.load(\"/content/mmQuad_filter-norm_to_500.npy\")\n",
        "data = np.concatenate((data1, data2), axis=0)\n",
        "# dataq = np.load(\"/content/G4_filter-norm_to_500.npy\")\n",
        "# data = np.concatenate((data, dataq), axis=0)\n",
        "# dataq = np.load(\"/content/zdna2016_filter-norm_to_500.npy\")\n",
        "# data = np.concatenate((data, dataq), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyUzgcbQlO7y"
      },
      "outputs": [],
      "source": [
        "# saved_state_dict = torch.load('./models/20231002120536/model_gen_last.pkl')\n",
        "\n",
        "# # Initialize a new model with the current architecture\n",
        "# model_gen = G4GANGenerator(model_size, seq_len, onehot_len)\n",
        "# model_gen.eval()\n",
        "\n",
        "# # Copy the weights from the saved model to the new model\n",
        "# model_gen.conv1.weight.data.copy_(saved_state_dict['conv1.weight'])\n",
        "# model_gen.conv1.bias.data.copy_(saved_state_dict['conv1.bias'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_Fofs3u3iGN"
      },
      "outputs": [],
      "source": [
        "weights_path = 'wgan_zdna.pkl'\n",
        "model_size = 32\n",
        "seq_len = 5\n",
        "onehot_len = 65\n",
        "hidden_state_len = 128\n",
        "g4gan = load_wgan_generator(weights_path, model_size, seq_len,\n",
        "                             onehot_len)\n",
        "g4gan.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue4wzaRXgnMq"
      },
      "outputs": [],
      "source": [
        "input = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mSc3u31rBbD",
        "outputId": "e01406e7-5a90-4534-c0a1-c3af9a8b17f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1177297"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oo7g8g_JrWMy"
      },
      "outputs": [],
      "source": [
        "def sample_fake_data(generator, batch_size, hidden_state_len):\n",
        "    fake_data = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(0, input.shape[0], batch_size):\n",
        "            noise = torch.Tensor(batch_size, hidden_state_len).uniform_(-1, 1)\n",
        "            fake = generator(noise)\n",
        "            (values, indices_hot) = fake.max(2)\n",
        "            fake[:, :, :] = 0\n",
        "            indices_hot = indices_hot.view(indices_hot.shape[0], indices_hot.shape[1], 1)\n",
        "            fake = fake.scatter_(2, indices_hot, 1)\n",
        "            fake_data.append(fake.detach().numpy())\n",
        "    return np.concatenate(fake_data, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFVOVKIIrdaP"
      },
      "outputs": [],
      "source": [
        "batch_size = 1000\n",
        "\n",
        "fake_samples = sample_fake_data(g4gan, batch_size, hidden_state_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2D9q2o9gORD"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    noise = torch.Tensor(input.shape[0], hidden_state_len).uniform_(-1, 1)\n",
        "    fake = g4gan(noise)\n",
        "    (values, indices_hot) = fake.max(2)\n",
        "    fake[:, :, :] = 0\n",
        "    indices_hot = indices_hot.view(indices_hot.shape[0], indices_hot.shape[1], 1)\n",
        "    fake = fake.scatter_(2, indices_hot, 1)\n",
        "    input_fake = fake.detach().numpy()\n",
        "\n",
        "# num_g4 = input.shape[0]\n",
        "# num_test = int(np.ceil(num_g4 * test_ratio))\n",
        "# num_train = num_g4 - num_test\n",
        "# indices = np.arange(num_g4)\n",
        "# np.random.shuffle(indices)\n",
        "# train_data_indices = indices[:num_train]\n",
        "# test_data_indices = indices[num_train:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7TndYpKiYel",
        "outputId": "7d8cd228-d463-42ab-e3cd-2cf0bcf8e7fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1178000, 512, 5)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fake_samples.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tt3CR6aknWDw"
      },
      "outputs": [],
      "source": [
        "new_data = fake_samples[:, :100, :5]\n",
        "\n",
        "# Extract the cut values\n",
        "cut_values = fake_samples[:, :, 5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8fXYJr3n4j3",
        "outputId": "4fbf9ed8-872f-48ba-f776-038be0090553"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([], shape=(0, 1), dtype=float32)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cut_values.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaELlqPDoi4d",
        "outputId": "d07ac388-16a2-4431-e40e-20f1ada06e28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 5)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ-jgBBZtqS9",
        "outputId": "a38a7a3a-a5a4-47ee-9c8f-cef99fcd5cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1178000, 100, 5)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9c_8C63tpPn"
      },
      "outputs": [],
      "source": [
        "reverse_codes = {\n",
        "    'A': [1., 0., 0., 0., 0.],\n",
        "    'T': [0., 1., 0., 0., 0.],\n",
        "    'G': [0., 0., 1., 0., 0.],\n",
        "    'C': [0., 0., 0., 1., 0.],\n",
        "    'N': [0., 0., 0., 0., 1.],\n",
        "}\n",
        "\n",
        "def decode_data(encoded_sequences):\n",
        "    decoded_sequences = []\n",
        "\n",
        "    for sequence in encoded_sequences:\n",
        "        decoded_sequence = ''\n",
        "        for encoding in sequence:\n",
        "            for char, code in reverse_codes.items():\n",
        "                if torch.equal(encoding, torch.tensor(code, dtype=torch.float64)):\n",
        "                    decoded_sequence += char\n",
        "                    break\n",
        "        decoded_sequences.append(decoded_sequence)\n",
        "\n",
        "    return decoded_sequences\n",
        "\n",
        "decoded_seqs = decode_data([torch.tensor(seq, dtype=torch.float64) for seq in new_data])\n",
        "\n",
        "decoded_seqs_np = np.array(decoded_seqs)\n",
        "\n",
        "with open('generated_sequences.txt', 'w') as f:\n",
        "    for seq in decoded_seqs:\n",
        "        f.write(seq + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAcGGMa4EL1E"
      },
      "outputs": [],
      "source": [
        "bedWK_df = pd.read_csv('/content/drive/My Drive/data_for_gans/data/hg19_zdna/raw/WuKou16_filter_norm_to_512.bed', sep='\\t', comment='t', header=None)\n",
        "bed16_df = pd.read_csv('/content/drive/My Drive/data_for_gans/data/hg19_zdna/raw/zdna2016_filter_norm_to_512.bed', sep='\\t', comment='t', header=None)\n",
        "bedG_df = pd.read_csv('/content/drive/My Drive/data_for_gans/G4_Chip_seq_filter_norm_to_500.bed', sep='\\t', comment='t', header=None)\n",
        "bed = pd.read_csv('/content/HDNA_norm_to_500.bed', sep='\\t', comment='t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-Zl3agzNyX3"
      },
      "outputs": [],
      "source": [
        "bed1 = pd.read_csv('/content/mmHDNA_norm_to_500.bed', sep='\\t', comment='t', header=None)\n",
        "bed2 = pd.read_csv('/content/Quadruplex_norm_to_500.bed', sep='\\t', comment='t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeY884KRENX_"
      },
      "outputs": [],
      "source": [
        "# un_bed_dataset = pd.concat([bedWK_df, bed16_df]).reset_index(drop=True)\n",
        "# un_bed_dataset = pd.concat([un_bed_dataset, bedG_df]).reset_index(drop=True)\n",
        "# un_bed_dataset = pd.concat([un_bed_dataset, bed]).reset_index(drop=True)\n",
        "un_bed_dataset = pd.concat([bed1, bed2]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV6pzv6-O8EY"
      },
      "outputs": [],
      "source": [
        "bed1.columns = ['chrom', 'chromStart', 'chromEnd']\n",
        "bed2.columns = ['chrom', 'chromStart', 'chromEnd']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvoqzCMhBuAa"
      },
      "outputs": [],
      "source": [
        "# bed = pd.read_csv('/content/HDNA_norm_to_500.bed', sep='\\t', comment='t', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2U8won5EOj3"
      },
      "outputs": [],
      "source": [
        "un_bed_dataset.columns = ['chrom', 'chromStart', 'chromEnd']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FviVoQZUIH3U",
        "outputId": "4b6a078b-4b1c-42c6-8398-741ce1a519e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1211161, 3)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "un_bed_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_DlNGbmD0UJ"
      },
      "outputs": [],
      "source": [
        "df_gen_sequences = pd.DataFrame({\"chrom\": un_bed_dataset[:len(decoded_seqs_np)].chrom, \"raw_sequence\": decoded_seqs_np})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY0enWTBI8qN"
      },
      "outputs": [],
      "source": [
        "df_gen_sequences_to_fasta = df_gen_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-GBEl31D36V"
      },
      "outputs": [],
      "source": [
        "fasta_lines = []\n",
        "\n",
        "for index, row in df_gen_sequences_to_fasta.iterrows():\n",
        "    chrom = row['chrom']\n",
        "    sequence = row['raw_sequence']\n",
        "\n",
        "    fasta_lines.append(f'>{chrom}\\n{sequence}\\n')\n",
        "\n",
        "fasta_file_path = '/content/mm_Quad+H_wgan.fasta'\n",
        "with open(fasta_file_path, 'w') as fasta_file:\n",
        "    fasta_file.writelines(fasta_lines)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}